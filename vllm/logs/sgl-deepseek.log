[33mTailing logs of job 14 on cluster 'benchmark'...[0m
[2m├── [0m[2mWaiting for task resources on 1 node.[0m
[2m└── [0mJob started. Streaming logs... [2m(Ctrl-C to exit log streaming; job will not be killed)[0m
[36m(vllm-benchmark, pid=7329)[0m Sun Apr 20 01:32:30 2025       
[36m(vllm-benchmark, pid=7329)[0m +-----------------------------------------------------------------------------------------+
[36m(vllm-benchmark, pid=7329)[0m | NVIDIA-SMI 550.127.08             Driver Version: 550.127.08     CUDA Version: 12.4     |
[36m(vllm-benchmark, pid=7329)[0m |-----------------------------------------+------------------------+----------------------+
[36m(vllm-benchmark, pid=7329)[0m | GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
[36m(vllm-benchmark, pid=7329)[0m | Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
[36m(vllm-benchmark, pid=7329)[0m |                                         |                        |               MIG M. |
[36m(vllm-benchmark, pid=7329)[0m |=========================================+========================+======================|
[36m(vllm-benchmark, pid=7329)[0m |   0  NVIDIA H200                    On  |   00000000:8D:00.0 Off |                    0 |
[36m(vllm-benchmark, pid=7329)[0m | N/A   36C    P0             78W /  700W |       1MiB / 143771MiB |      0%      Default |
[36m(vllm-benchmark, pid=7329)[0m |                                         |                        |             Disabled |
[36m(vllm-benchmark, pid=7329)[0m +-----------------------------------------+------------------------+----------------------+
[36m(vllm-benchmark, pid=7329)[0m |   1  NVIDIA H200                    On  |   00000000:91:00.0 Off |                    0 |
[36m(vllm-benchmark, pid=7329)[0m | N/A   32C    P0             78W /  700W |       1MiB / 143771MiB |      0%      Default |
[36m(vllm-benchmark, pid=7329)[0m |                                         |                        |             Disabled |
[36m(vllm-benchmark, pid=7329)[0m +-----------------------------------------+------------------------+----------------------+
[36m(vllm-benchmark, pid=7329)[0m |   2  NVIDIA H200                    On  |   00000000:95:00.0 Off |                    0 |
[36m(vllm-benchmark, pid=7329)[0m | N/A   35C    P0             83W /  700W |       1MiB / 143771MiB |      0%      Default |
[36m(vllm-benchmark, pid=7329)[0m |                                         |                        |             Disabled |
[36m(vllm-benchmark, pid=7329)[0m +-----------------------------------------+------------------------+----------------------+
[36m(vllm-benchmark, pid=7329)[0m |   3  NVIDIA H200                    On  |   00000000:99:00.0 Off |                    0 |
[36m(vllm-benchmark, pid=7329)[0m | N/A   31C    P0             78W /  700W |       1MiB / 143771MiB |      0%      Default |
[36m(vllm-benchmark, pid=7329)[0m |                                         |                        |             Disabled |
[36m(vllm-benchmark, pid=7329)[0m +-----------------------------------------+------------------------+----------------------+
[36m(vllm-benchmark, pid=7329)[0m |   4  NVIDIA H200                    On  |   00000000:AB:00.0 Off |                    0 |
[36m(vllm-benchmark, pid=7329)[0m | N/A   36C    P0             79W /  700W |       1MiB / 143771MiB |      0%      Default |
[36m(vllm-benchmark, pid=7329)[0m |                                         |                        |             Disabled |
[36m(vllm-benchmark, pid=7329)[0m +-----------------------------------------+------------------------+----------------------+
[36m(vllm-benchmark, pid=7329)[0m |   5  NVIDIA H200                    On  |   00000000:AF:00.0 Off |                    0 |
[36m(vllm-benchmark, pid=7329)[0m | N/A   32C    P0             78W /  700W |       1MiB / 143771MiB |      0%      Default |
[36m(vllm-benchmark, pid=7329)[0m |                                         |                        |             Disabled |
[36m(vllm-benchmark, pid=7329)[0m +-----------------------------------------+------------------------+----------------------+
[36m(vllm-benchmark, pid=7329)[0m |   6  NVIDIA H200                    On  |   00000000:B3:00.0 Off |                    0 |
[36m(vllm-benchmark, pid=7329)[0m | N/A   34C    P0             78W /  700W |       1MiB / 143771MiB |      0%      Default |
[36m(vllm-benchmark, pid=7329)[0m |                                         |                        |             Disabled |
[36m(vllm-benchmark, pid=7329)[0m +-----------------------------------------+------------------------+----------------------+
[36m(vllm-benchmark, pid=7329)[0m |   7  NVIDIA H200                    On  |   00000000:B7:00.0 Off |                    0 |
[36m(vllm-benchmark, pid=7329)[0m | N/A   32C    P0             78W /  700W |       1MiB / 143771MiB |      0%      Default |
[36m(vllm-benchmark, pid=7329)[0m |                                         |                        |             Disabled |
[36m(vllm-benchmark, pid=7329)[0m +-----------------------------------------+------------------------+----------------------+
[36m(vllm-benchmark, pid=7329)[0m                                                                                          
[36m(vllm-benchmark, pid=7329)[0m +-----------------------------------------------------------------------------------------+
[36m(vllm-benchmark, pid=7329)[0m | Processes:                                                                              |
[36m(vllm-benchmark, pid=7329)[0m |  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
[36m(vllm-benchmark, pid=7329)[0m |        ID   ID                                                               Usage      |
[36m(vllm-benchmark, pid=7329)[0m |=========================================================================================|
[36m(vllm-benchmark, pid=7329)[0m |  No running processes found                                                             |
[36m(vllm-benchmark, pid=7329)[0m +-----------------------------------------------------------------------------------------+
[36m(vllm-benchmark, pid=7329)[0m Architecture:                         x86_64
[36m(vllm-benchmark, pid=7329)[0m CPU op-mode(s):                       32-bit, 64-bit
[36m(vllm-benchmark, pid=7329)[0m Address sizes:                        43 bits physical, 57 bits virtual
[36m(vllm-benchmark, pid=7329)[0m Byte Order:                           Little Endian
[36m(vllm-benchmark, pid=7329)[0m CPU(s):                               128
[36m(vllm-benchmark, pid=7329)[0m On-line CPU(s) list:                  0-127
[36m(vllm-benchmark, pid=7329)[0m Vendor ID:                            GenuineIntel
[36m(vllm-benchmark, pid=7329)[0m Model name:                           Intel(R) Xeon(R) Platinum 8468
[36m(vllm-benchmark, pid=7329)[0m CPU family:                           6
[36m(vllm-benchmark, pid=7329)[0m Model:                                143
[36m(vllm-benchmark, pid=7329)[0m Thread(s) per core:                   2
[36m(vllm-benchmark, pid=7329)[0m Core(s) per socket:                   32
[36m(vllm-benchmark, pid=7329)[0m Socket(s):                            2
[36m(vllm-benchmark, pid=7329)[0m Stepping:                             8
[36m(vllm-benchmark, pid=7329)[0m BogoMIPS:                             4200.00
[36m(vllm-benchmark, pid=7329)[0m Flags:                                fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon rep_good nopl xtopology cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch cpuid_fault invpcid_single ssbd ibrs ibpb stibp ibrs_enhanced fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid avx512f avx512dq rdseed adx smap avx512ifma clflushopt clwb avx512cd sha_ni avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves avx_vnni avx512_bf16 wbnoinvd arat avx512vbmi umip pku ospke waitpkg avx512_vbmi2 gfni vaes vpclmulqdq avx512_vnni avx512_bitalg avx512_vpopcntdq la57 rdpid bus_lock_detect cldemote movdiri movdir64b fsrm md_clear serialize tsxldtrk avx512_fp16 arch_capabilities
[36m(vllm-benchmark, pid=7329)[0m Hypervisor vendor:                    KVM
[36m(vllm-benchmark, pid=7329)[0m Virtualization type:                  full
[36m(vllm-benchmark, pid=7329)[0m L1d cache:                            4 MiB (128 instances)
[36m(vllm-benchmark, pid=7329)[0m L1i cache:                            4 MiB (128 instances)
[36m(vllm-benchmark, pid=7329)[0m L2 cache:                             256 MiB (64 instances)
[36m(vllm-benchmark, pid=7329)[0m L3 cache:                             32 MiB (2 instances)
[36m(vllm-benchmark, pid=7329)[0m NUMA node(s):                         2
[36m(vllm-benchmark, pid=7329)[0m NUMA node0 CPU(s):                    0-63
[36m(vllm-benchmark, pid=7329)[0m NUMA node1 CPU(s):                    64-127
[36m(vllm-benchmark, pid=7329)[0m Vulnerability Gather data sampling:   Not affected
[36m(vllm-benchmark, pid=7329)[0m Vulnerability Itlb multihit:          Not affected
[36m(vllm-benchmark, pid=7329)[0m Vulnerability L1tf:                   Not affected
[36m(vllm-benchmark, pid=7329)[0m Vulnerability Mds:                    Not affected
[36m(vllm-benchmark, pid=7329)[0m Vulnerability Meltdown:               Not affected
[36m(vllm-benchmark, pid=7329)[0m Vulnerability Mmio stale data:        Unknown: No mitigations
[36m(vllm-benchmark, pid=7329)[0m Vulnerability Reg file data sampling: Not affected
[36m(vllm-benchmark, pid=7329)[0m Vulnerability Retbleed:               Not affected
[36m(vllm-benchmark, pid=7329)[0m Vulnerability Spec rstack overflow:   Not affected
[36m(vllm-benchmark, pid=7329)[0m Vulnerability Spec store bypass:      Mitigation; Speculative Store Bypass disabled via prctl and seccomp
[36m(vllm-benchmark, pid=7329)[0m Vulnerability Spectre v1:             Mitigation; usercopy/swapgs barriers and __user pointer sanitization
[36m(vllm-benchmark, pid=7329)[0m Vulnerability Spectre v2:             Mitigation; Enhanced / Automatic IBRS; IBPB conditional; RSB filling; PBRSB-eIBRS SW sequence; BHI SW loop, KVM SW loop
[36m(vllm-benchmark, pid=7329)[0m Vulnerability Srbds:                  Not affected
[36m(vllm-benchmark, pid=7329)[0m Vulnerability Tsx async abort:        Mitigation; TSX disabled
[36m(vllm-benchmark, pid=7329)[0m Waiting for sgl server to start...
[36m(vllm-benchmark, pid=7329)[0m Waiting for sgl server to start...
[36m(vllm-benchmark, pid=7329)[0m Waiting for sgl server to start...
[36m(vllm-benchmark, pid=7329)[0m Waiting for sgl server to start...
[36m(vllm-benchmark, pid=7329)[0m Waiting for sgl server to start...
[36m(vllm-benchmark, pid=7329)[0m Waiting for sgl server to start...
[36m(vllm-benchmark, pid=7329)[0m Waiting for sgl server to start...
[36m(vllm-benchmark, pid=7329)[0m Waiting for sgl server to start...
[36m(vllm-benchmark, pid=7329)[0m Waiting for sgl server to start...
[36m(vllm-benchmark, pid=7329)[0m Waiting for sgl server to start...
[36m(vllm-benchmark, pid=7329)[0m Waiting for sgl server to start...
[36m(vllm-benchmark, pid=7329)[0m Waiting for sgl server to start...
[36m(vllm-benchmark, pid=7329)[0m Waiting for sgl server to start...
[36m(vllm-benchmark, pid=7329)[0m Waiting for sgl server to start...
[36m(vllm-benchmark, pid=7329)[0m Waiting for sgl server to start...
[36m(vllm-benchmark, pid=7329)[0m Waiting for sgl server to start...
[36m(vllm-benchmark, pid=7329)[0m Waiting for sgl server to start...
[36m(vllm-benchmark, pid=7329)[0m Waiting for sgl server to start...
[36m(vllm-benchmark, pid=7329)[0m Waiting for sgl server to start...
[36m(vllm-benchmark, pid=7329)[0m Waiting for sgl server to start...
[36m(vllm-benchmark, pid=7329)[0m Waiting for sgl server to start...
[36m(vllm-benchmark, pid=7329)[0m Waiting for sgl server to start...
[36m(vllm-benchmark, pid=7329)[0m Waiting for sgl server to start...
[36m(vllm-benchmark, pid=7329)[0m Waiting for sgl server to start...
[36m(vllm-benchmark, pid=7329)[0m Waiting for sgl server to start...
[36m(vllm-benchmark, pid=7329)[0m Waiting for sgl server to start...
[36m(vllm-benchmark, pid=7329)[0m Waiting for sgl server to start...
[36m(vllm-benchmark, pid=7329)[0m Waiting for sgl server to start...
[36m(vllm-benchmark, pid=7329)[0m sgl server started
[36m(vllm-benchmark, pid=7329)[0m + for pair in "1000,2000" "5000,1000" "10000,500" "30000,100" "sharegpt"
[36m(vllm-benchmark, pid=7329)[0m + '[' sgl == trt ']'
[36m(vllm-benchmark, pid=7329)[0m + just run-scenario sgl deepseek-r1 1000,2000
[36m(vllm-benchmark, pid=7329)[0m + just _ensure-results-dir deepseek-r1
[36m(vllm-benchmark, pid=7329)[0m mkdir -p results/deepseek-r1
[36m(vllm-benchmark, pid=7329)[0m + '[' sgl '!=' vllm ']'
[36m(vllm-benchmark, pid=7329)[0m + '[' sgl '!=' sgl ']'
[36m(vllm-benchmark, pid=7329)[0m ++ just _get-model-path deepseek-r1
[36m(vllm-benchmark, pid=7329)[0m + MODEL_PATH=deepseek-ai/DeepSeek-R1
[36m(vllm-benchmark, pid=7329)[0m ++ echo 1000,2000
[36m(vllm-benchmark, pid=7329)[0m ++ cut -d, -f1
[36m(vllm-benchmark, pid=7329)[0m + INPUT_LEN=1000
[36m(vllm-benchmark, pid=7329)[0m ++ echo 1000,2000
[36m(vllm-benchmark, pid=7329)[0m ++ cut -d, -f2
[36m(vllm-benchmark, pid=7329)[0m + OUTPUT_LEN=2000
[36m(vllm-benchmark, pid=7329)[0m + [[ '' == \s\g\l ]]
[36m(vllm-benchmark, pid=7329)[0m + [[ 1000,2000 == \s\h\a\r\e\g\p\t ]]
[36m(vllm-benchmark, pid=7329)[0m + uv run --with-requirements requirements-benchmark.txt vllm-benchmarks/benchmarks/benchmark_serving.py --model deepseek-ai/DeepSeek-R1 --dataset-name random --ignore-eos --num-prompts 50 --request-rate 10 --random-input-len 1000 --random-output-len 2000 --save-result --result-dir results/deepseek-r1 --result-filename sgl-1000-2000-.json
[36m(vllm-benchmark, pid=7329)[0m INFO 04-20 01:35:04 [__init__.py:239] Automatically detected platform cuda.
[36m(vllm-benchmark, pid=7329)[0m Namespace(backend='vllm', base_url=None, host='127.0.0.1', port=8000, endpoint='/v1/completions', dataset_name='random', dataset_path=None, max_concurrency=None, model='deepseek-ai/DeepSeek-R1', tokenizer=None, use_beam_search=False, num_prompts=50, logprobs=None, request_rate=10.0, burstiness=1.0, seed=0, trust_remote_code=False, disable_tqdm=False, profile=False, save_result=True, save_detailed=False, metadata=None, result_dir='results/deepseek-r1', result_filename='sgl-1000-2000-.json', ignore_eos=True, percentile_metrics='ttft,tpot,itl', metric_percentiles='99', goodput=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, sharegpt_output_len=None, random_input_len=1000, random_output_len=2000, random_range_ratio=0.0, random_prefix_len=0, hf_subset=None, hf_split=None, hf_output_len=None, top_p=None, top_k=None, min_p=None, temperature=None, tokenizer_mode='auto', served_model_name=None, lora_modules=None)
[36m(vllm-benchmark, pid=7329)[0m Starting initial single prompt test run...
[36m(vllm-benchmark, pid=7329)[0m Initial test run completed. Starting main benchmark run...
[36m(vllm-benchmark, pid=7329)[0m Traffic request rate: 10.0
[36m(vllm-benchmark, pid=7329)[0m Burstiness factor: 1.0 (Poisson process)
[36m(vllm-benchmark, pid=7329)[0m Maximum request concurrency: None
[36m(vllm-benchmark, pid=7329)[0m 
[36m(vllm-benchmark, pid=7329)[0m   0%|          | 0/50 [00:00<?, ?it/s]
  2%|▏         | 1/50 [01:42<1:23:32, 102.31s/it]
100%|██████████| 50/50 [01:42<00:00,  2.05s/it]  
[36m(vllm-benchmark, pid=7329)[0m ============ Serving Benchmark Result ============
[36m(vllm-benchmark, pid=7329)[0m Successful requests:                     50        
[36m(vllm-benchmark, pid=7329)[0m Benchmark duration (s):                  102.39    
[36m(vllm-benchmark, pid=7329)[0m Total input tokens:                      50000     
[36m(vllm-benchmark, pid=7329)[0m Total generated tokens:                  100000    
[36m(vllm-benchmark, pid=7329)[0m Request throughput (req/s):              0.49      
[36m(vllm-benchmark, pid=7329)[0m Output token throughput (tok/s):         976.68    
[36m(vllm-benchmark, pid=7329)[0m Total Token throughput (tok/s):          1465.01   
[36m(vllm-benchmark, pid=7329)[0m ---------------Time to First Token----------------
[36m(vllm-benchmark, pid=7329)[0m Mean TTFT (ms):                          3371.52   
[36m(vllm-benchmark, pid=7329)[0m Median TTFT (ms):                        3414.30   
[36m(vllm-benchmark, pid=7329)[0m P99 TTFT (ms):                           4424.53   
[36m(vllm-benchmark, pid=7329)[0m -----Time per Output Token (excl. 1st token)------
[36m(vllm-benchmark, pid=7329)[0m Mean TPOT (ms):                          48.42     
[36m(vllm-benchmark, pid=7329)[0m Median TPOT (ms):                        48.44     
[36m(vllm-benchmark, pid=7329)[0m P99 TPOT (ms):                           50.09     
[36m(vllm-benchmark, pid=7329)[0m ---------------Inter-token Latency----------------
[36m(vllm-benchmark, pid=7329)[0m Mean ITL (ms):                           48.42     
[36m(vllm-benchmark, pid=7329)[0m Median ITL (ms):                         46.69     
[36m(vllm-benchmark, pid=7329)[0m P99 ITL (ms):                            49.01     
[36m(vllm-benchmark, pid=7329)[0m ==================================================
[36m(vllm-benchmark, pid=7329)[0m + sleep 6
[36m(vllm-benchmark, pid=7329)[0m + for pair in "1000,2000" "5000,1000" "10000,500" "30000,100" "sharegpt"
[36m(vllm-benchmark, pid=7329)[0m + '[' sgl == trt ']'
[36m(vllm-benchmark, pid=7329)[0m + just run-scenario sgl deepseek-r1 5000,1000
[36m(vllm-benchmark, pid=7329)[0m + just _ensure-results-dir deepseek-r1
[36m(vllm-benchmark, pid=7329)[0m mkdir -p results/deepseek-r1
[36m(vllm-benchmark, pid=7329)[0m + '[' sgl '!=' vllm ']'
[36m(vllm-benchmark, pid=7329)[0m + '[' sgl '!=' sgl ']'
[36m(vllm-benchmark, pid=7329)[0m ++ just _get-model-path deepseek-r1
[36m(vllm-benchmark, pid=7329)[0m + MODEL_PATH=deepseek-ai/DeepSeek-R1
[36m(vllm-benchmark, pid=7329)[0m ++ echo 5000,1000
[36m(vllm-benchmark, pid=7329)[0m ++ cut -d, -f1
[36m(vllm-benchmark, pid=7329)[0m + INPUT_LEN=5000
[36m(vllm-benchmark, pid=7329)[0m ++ echo 5000,1000
[36m(vllm-benchmark, pid=7329)[0m ++ cut -d, -f2
[36m(vllm-benchmark, pid=7329)[0m + OUTPUT_LEN=1000
[36m(vllm-benchmark, pid=7329)[0m + [[ '' == \s\g\l ]]
[36m(vllm-benchmark, pid=7329)[0m + [[ 5000,1000 == \s\h\a\r\e\g\p\t ]]
[36m(vllm-benchmark, pid=7329)[0m + uv run --with-requirements requirements-benchmark.txt vllm-benchmarks/benchmarks/benchmark_serving.py --model deepseek-ai/DeepSeek-R1 --dataset-name random --ignore-eos --num-prompts 50 --request-rate 10 --random-input-len 5000 --random-output-len 1000 --save-result --result-dir results/deepseek-r1 --result-filename sgl-5000-1000-.json
[36m(vllm-benchmark, pid=7329)[0m INFO 04-20 01:37:47 [__init__.py:239] Automatically detected platform cuda.
[36m(vllm-benchmark, pid=7329)[0m Namespace(backend='vllm', base_url=None, host='127.0.0.1', port=8000, endpoint='/v1/completions', dataset_name='random', dataset_path=None, max_concurrency=None, model='deepseek-ai/DeepSeek-R1', tokenizer=None, use_beam_search=False, num_prompts=50, logprobs=None, request_rate=10.0, burstiness=1.0, seed=0, trust_remote_code=False, disable_tqdm=False, profile=False, save_result=True, save_detailed=False, metadata=None, result_dir='results/deepseek-r1', result_filename='sgl-5000-1000-.json', ignore_eos=True, percentile_metrics='ttft,tpot,itl', metric_percentiles='99', goodput=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, sharegpt_output_len=None, random_input_len=5000, random_output_len=1000, random_range_ratio=0.0, random_prefix_len=0, hf_subset=None, hf_split=None, hf_output_len=None, top_p=None, top_k=None, min_p=None, temperature=None, tokenizer_mode='auto', served_model_name=None, lora_modules=None)
[36m(vllm-benchmark, pid=7329)[0m Starting initial single prompt test run...
[36m(vllm-benchmark, pid=7329)[0m Initial test run completed. Starting main benchmark run...
[36m(vllm-benchmark, pid=7329)[0m Traffic request rate: 10.0
[36m(vllm-benchmark, pid=7329)[0m Burstiness factor: 1.0 (Poisson process)
[36m(vllm-benchmark, pid=7329)[0m Maximum request concurrency: None
[36m(vllm-benchmark, pid=7329)[0m 
[36m(vllm-benchmark, pid=7329)[0m   0%|          | 0/50 [00:00<?, ?it/s]
[36m(vllm-benchmark, pid=7329)[0m   2%|▏         | 1/50 [01:02<51:05, 62.56s/it]
 74%|███████▍  | 37/50 [01:02<00:15,  1.20s/it]
100%|██████████| 50/50 [01:02<00:00,  1.26s/it]
[36m(vllm-benchmark, pid=7329)[0m ============ Serving Benchmark Result ============
[36m(vllm-benchmark, pid=7329)[0m Successful requests:                     50        
[36m(vllm-benchmark, pid=7329)[0m Benchmark duration (s):                  62.78     
[36m(vllm-benchmark, pid=7329)[0m Total input tokens:                      250000    
[36m(vllm-benchmark, pid=7329)[0m Total generated tokens:                  50000     
[36m(vllm-benchmark, pid=7329)[0m Request throughput (req/s):              0.80      
[36m(vllm-benchmark, pid=7329)[0m Output token throughput (tok/s):         796.41    
[36m(vllm-benchmark, pid=7329)[0m Total Token throughput (tok/s):          4778.45   
[36m(vllm-benchmark, pid=7329)[0m ---------------Time to First Token----------------
[36m(vllm-benchmark, pid=7329)[0m Mean TTFT (ms):                          10377.54  
[36m(vllm-benchmark, pid=7329)[0m Median TTFT (ms):                        10671.21  
[36m(vllm-benchmark, pid=7329)[0m P99 TTFT (ms):                           15858.86  
[36m(vllm-benchmark, pid=7329)[0m -----Time per Output Token (excl. 1st token)------
[36m(vllm-benchmark, pid=7329)[0m Mean TPOT (ms):                          50.16     
[36m(vllm-benchmark, pid=7329)[0m Median TPOT (ms):                        49.85     
[36m(vllm-benchmark, pid=7329)[0m P99 TPOT (ms):                           58.27     
[36m(vllm-benchmark, pid=7329)[0m ---------------Inter-token Latency----------------
[36m(vllm-benchmark, pid=7329)[0m Mean ITL (ms):                           50.16     
[36m(vllm-benchmark, pid=7329)[0m Median ITL (ms):                         42.29     
[36m(vllm-benchmark, pid=7329)[0m P99 ITL (ms):                            45.26     
[36m(vllm-benchmark, pid=7329)[0m ==================================================
[36m(vllm-benchmark, pid=7329)[0m + sleep 6
[36m(vllm-benchmark, pid=7329)[0m + for pair in "1000,2000" "5000,1000" "10000,500" "30000,100" "sharegpt"
[36m(vllm-benchmark, pid=7329)[0m + '[' sgl == trt ']'
[36m(vllm-benchmark, pid=7329)[0m + just run-scenario sgl deepseek-r1 10000,500
[36m(vllm-benchmark, pid=7329)[0m + just _ensure-results-dir deepseek-r1
[36m(vllm-benchmark, pid=7329)[0m mkdir -p results/deepseek-r1
[36m(vllm-benchmark, pid=7329)[0m + '[' sgl '!=' vllm ']'
[36m(vllm-benchmark, pid=7329)[0m + '[' sgl '!=' sgl ']'
[36m(vllm-benchmark, pid=7329)[0m ++ just _get-model-path deepseek-r1
[36m(vllm-benchmark, pid=7329)[0m + MODEL_PATH=deepseek-ai/DeepSeek-R1
[36m(vllm-benchmark, pid=7329)[0m ++ echo 10000,500
[36m(vllm-benchmark, pid=7329)[0m ++ cut -d, -f1
[36m(vllm-benchmark, pid=7329)[0m + INPUT_LEN=10000
[36m(vllm-benchmark, pid=7329)[0m ++ echo 10000,500
[36m(vllm-benchmark, pid=7329)[0m ++ cut -d, -f2
[36m(vllm-benchmark, pid=7329)[0m + OUTPUT_LEN=500
[36m(vllm-benchmark, pid=7329)[0m + [[ '' == \s\g\l ]]
[36m(vllm-benchmark, pid=7329)[0m + [[ 10000,500 == \s\h\a\r\e\g\p\t ]]
[36m(vllm-benchmark, pid=7329)[0m + uv run --with-requirements requirements-benchmark.txt vllm-benchmarks/benchmarks/benchmark_serving.py --model deepseek-ai/DeepSeek-R1 --dataset-name random --ignore-eos --num-prompts 50 --request-rate 10 --random-input-len 10000 --random-output-len 500 --save-result --result-dir results/deepseek-r1 --result-filename sgl-10000-500-.json
[36m(vllm-benchmark, pid=7329)[0m INFO 04-20 01:39:29 [__init__.py:239] Automatically detected platform cuda.
[36m(vllm-benchmark, pid=7329)[0m Namespace(backend='vllm', base_url=None, host='127.0.0.1', port=8000, endpoint='/v1/completions', dataset_name='random', dataset_path=None, max_concurrency=None, model='deepseek-ai/DeepSeek-R1', tokenizer=None, use_beam_search=False, num_prompts=50, logprobs=None, request_rate=10.0, burstiness=1.0, seed=0, trust_remote_code=False, disable_tqdm=False, profile=False, save_result=True, save_detailed=False, metadata=None, result_dir='results/deepseek-r1', result_filename='sgl-10000-500-.json', ignore_eos=True, percentile_metrics='ttft,tpot,itl', metric_percentiles='99', goodput=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, sharegpt_output_len=None, random_input_len=10000, random_output_len=500, random_range_ratio=0.0, random_prefix_len=0, hf_subset=None, hf_split=None, hf_output_len=None, top_p=None, top_k=None, min_p=None, temperature=None, tokenizer_mode='auto', served_model_name=None, lora_modules=None)
[36m(vllm-benchmark, pid=7329)[0m Starting initial single prompt test run...
[36m(vllm-benchmark, pid=7329)[0m Initial test run completed. Starting main benchmark run...
[36m(vllm-benchmark, pid=7329)[0m Traffic request rate: 10.0
[36m(vllm-benchmark, pid=7329)[0m Burstiness factor: 1.0 (Poisson process)
[36m(vllm-benchmark, pid=7329)[0m Maximum request concurrency: None
[36m(vllm-benchmark, pid=7329)[0m 
[36m(vllm-benchmark, pid=7329)[0m   0%|          | 0/50 [00:00<?, ?it/s]
[36m(vllm-benchmark, pid=7329)[0m   2%|▏         | 1/50 [01:05<53:29, 65.51s/it]
[36m(vllm-benchmark, pid=7329)[0m  50%|█████     | 25/50 [01:05<00:46,  1.86s/it]
 90%|█████████ | 45/50 [01:05<00:04,  1.15it/s]
100%|██████████| 50/50 [01:05<00:00,  1.32s/it]
[36m(vllm-benchmark, pid=7329)[0m ============ Serving Benchmark Result ============
[36m(vllm-benchmark, pid=7329)[0m Successful requests:                     50        
[36m(vllm-benchmark, pid=7329)[0m Benchmark duration (s):                  65.90     
[36m(vllm-benchmark, pid=7329)[0m Total input tokens:                      500000    
[36m(vllm-benchmark, pid=7329)[0m Total generated tokens:                  25000     
[36m(vllm-benchmark, pid=7329)[0m Request throughput (req/s):              0.76      
[36m(vllm-benchmark, pid=7329)[0m Output token throughput (tok/s):         379.36    
[36m(vllm-benchmark, pid=7329)[0m Total Token throughput (tok/s):          7966.55   
[36m(vllm-benchmark, pid=7329)[0m ---------------Time to First Token----------------
[36m(vllm-benchmark, pid=7329)[0m Mean TTFT (ms):                          22726.30  
[36m(vllm-benchmark, pid=7329)[0m Median TTFT (ms):                        24071.20  
[36m(vllm-benchmark, pid=7329)[0m P99 TTFT (ms):                           38589.53  
[36m(vllm-benchmark, pid=7329)[0m -----Time per Output Token (excl. 1st token)------
[36m(vllm-benchmark, pid=7329)[0m Mean TPOT (ms):                          81.71     
[36m(vllm-benchmark, pid=7329)[0m Median TPOT (ms):                        79.46     
[36m(vllm-benchmark, pid=7329)[0m P99 TPOT (ms):                           117.25    
[36m(vllm-benchmark, pid=7329)[0m ---------------Inter-token Latency----------------
[36m(vllm-benchmark, pid=7329)[0m Mean ITL (ms):                           81.71     
[36m(vllm-benchmark, pid=7329)[0m Median ITL (ms):                         45.86     
[36m(vllm-benchmark, pid=7329)[0m P99 ITL (ms):                            317.27    
[36m(vllm-benchmark, pid=7329)[0m ==================================================
[36m(vllm-benchmark, pid=7329)[0m + sleep 6
[36m(vllm-benchmark, pid=7329)[0m + for pair in "1000,2000" "5000,1000" "10000,500" "30000,100" "sharegpt"
[36m(vllm-benchmark, pid=7329)[0m + '[' sgl == trt ']'
[36m(vllm-benchmark, pid=7329)[0m + just run-scenario sgl deepseek-r1 30000,100
[36m(vllm-benchmark, pid=7329)[0m + just _ensure-results-dir deepseek-r1
[36m(vllm-benchmark, pid=7329)[0m mkdir -p results/deepseek-r1
[36m(vllm-benchmark, pid=7329)[0m + '[' sgl '!=' vllm ']'
[36m(vllm-benchmark, pid=7329)[0m + '[' sgl '!=' sgl ']'
[36m(vllm-benchmark, pid=7329)[0m ++ just _get-model-path deepseek-r1
[36m(vllm-benchmark, pid=7329)[0m + MODEL_PATH=deepseek-ai/DeepSeek-R1
[36m(vllm-benchmark, pid=7329)[0m ++ echo 30000,100
[36m(vllm-benchmark, pid=7329)[0m ++ cut -d, -f1
[36m(vllm-benchmark, pid=7329)[0m + INPUT_LEN=30000
[36m(vllm-benchmark, pid=7329)[0m ++ echo 30000,100
[36m(vllm-benchmark, pid=7329)[0m ++ cut -d, -f2
[36m(vllm-benchmark, pid=7329)[0m + OUTPUT_LEN=100
[36m(vllm-benchmark, pid=7329)[0m + [[ '' == \s\g\l ]]
[36m(vllm-benchmark, pid=7329)[0m + [[ 30000,100 == \s\h\a\r\e\g\p\t ]]
[36m(vllm-benchmark, pid=7329)[0m + uv run --with-requirements requirements-benchmark.txt vllm-benchmarks/benchmarks/benchmark_serving.py --model deepseek-ai/DeepSeek-R1 --dataset-name random --ignore-eos --num-prompts 50 --request-rate 10 --random-input-len 30000 --random-output-len 100 --save-result --result-dir results/deepseek-r1 --result-filename sgl-30000-100-.json
[36m(vllm-benchmark, pid=7329)[0m INFO 04-20 01:41:03 [__init__.py:239] Automatically detected platform cuda.
[36m(vllm-benchmark, pid=7329)[0m Namespace(backend='vllm', base_url=None, host='127.0.0.1', port=8000, endpoint='/v1/completions', dataset_name='random', dataset_path=None, max_concurrency=None, model='deepseek-ai/DeepSeek-R1', tokenizer=None, use_beam_search=False, num_prompts=50, logprobs=None, request_rate=10.0, burstiness=1.0, seed=0, trust_remote_code=False, disable_tqdm=False, profile=False, save_result=True, save_detailed=False, metadata=None, result_dir='results/deepseek-r1', result_filename='sgl-30000-100-.json', ignore_eos=True, percentile_metrics='ttft,tpot,itl', metric_percentiles='99', goodput=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, sharegpt_output_len=None, random_input_len=30000, random_output_len=100, random_range_ratio=0.0, random_prefix_len=0, hf_subset=None, hf_split=None, hf_output_len=None, top_p=None, top_k=None, min_p=None, temperature=None, tokenizer_mode='auto', served_model_name=None, lora_modules=None)
[36m(vllm-benchmark, pid=7329)[0m Starting initial single prompt test run...
[36m(vllm-benchmark, pid=7329)[0m Initial test run completed. Starting main benchmark run...
[36m(vllm-benchmark, pid=7329)[0m Traffic request rate: 10.0
[36m(vllm-benchmark, pid=7329)[0m Burstiness factor: 1.0 (Poisson process)
[36m(vllm-benchmark, pid=7329)[0m Maximum request concurrency: None
[36m(vllm-benchmark, pid=7329)[0m 
[36m(vllm-benchmark, pid=7329)[0m   0%|          | 0/50 [00:00<?, ?it/s]
[36m(vllm-benchmark, pid=7329)[0m   2%|▏         | 1/50 [02:25<1:58:47, 145.46s/it]
[36m(vllm-benchmark, pid=7329)[0m  38%|███▊      | 19/50 [02:25<02:48,  5.45s/it]  
[36m(vllm-benchmark, pid=7329)[0m  74%|███████▍  | 37/50 [02:26<00:30,  2.33s/it]
100%|██████████| 50/50 [02:26<00:00,  2.93s/it]
[36m(vllm-benchmark, pid=7329)[0m ============ Serving Benchmark Result ============
[36m(vllm-benchmark, pid=7329)[0m Successful requests:                     50        
[36m(vllm-benchmark, pid=7329)[0m Benchmark duration (s):                  146.74    
[36m(vllm-benchmark, pid=7329)[0m Total input tokens:                      1500000   
[36m(vllm-benchmark, pid=7329)[0m Total generated tokens:                  5000      
[36m(vllm-benchmark, pid=7329)[0m Request throughput (req/s):              0.34      
[36m(vllm-benchmark, pid=7329)[0m Output token throughput (tok/s):         34.07     
[36m(vllm-benchmark, pid=7329)[0m Total Token throughput (tok/s):          10256.51  
[36m(vllm-benchmark, pid=7329)[0m ---------------Time to First Token----------------
[36m(vllm-benchmark, pid=7329)[0m Mean TTFT (ms):                          75891.04  
[36m(vllm-benchmark, pid=7329)[0m Median TTFT (ms):                        82599.76  
[36m(vllm-benchmark, pid=7329)[0m P99 TTFT (ms):                           137474.68 
[36m(vllm-benchmark, pid=7329)[0m -----Time per Output Token (excl. 1st token)------
[36m(vllm-benchmark, pid=7329)[0m Mean TPOT (ms):                          685.03    
[36m(vllm-benchmark, pid=7329)[0m Median TPOT (ms):                        625.78    
[36m(vllm-benchmark, pid=7329)[0m P99 TPOT (ms):                           1267.57   
[36m(vllm-benchmark, pid=7329)[0m ---------------Inter-token Latency----------------
[36m(vllm-benchmark, pid=7329)[0m Mean ITL (ms):                           685.03    
[36m(vllm-benchmark, pid=7329)[0m Median ITL (ms):                         49.72     
[36m(vllm-benchmark, pid=7329)[0m P99 ITL (ms):                            720.82    
[36m(vllm-benchmark, pid=7329)[0m ==================================================
[36m(vllm-benchmark, pid=7329)[0m + sleep 6
[36m(vllm-benchmark, pid=7329)[0m + for pair in "1000,2000" "5000,1000" "10000,500" "30000,100" "sharegpt"
[36m(vllm-benchmark, pid=7329)[0m + '[' sgl == trt ']'
[36m(vllm-benchmark, pid=7329)[0m + just run-scenario sgl deepseek-r1 sharegpt
[36m(vllm-benchmark, pid=7329)[0m + just _ensure-results-dir deepseek-r1
[36m(vllm-benchmark, pid=7329)[0m mkdir -p results/deepseek-r1
[36m(vllm-benchmark, pid=7329)[0m + '[' sgl '!=' vllm ']'
[36m(vllm-benchmark, pid=7329)[0m + '[' sgl '!=' sgl ']'
[36m(vllm-benchmark, pid=7329)[0m ++ just _get-model-path deepseek-r1
[36m(vllm-benchmark, pid=7329)[0m + MODEL_PATH=deepseek-ai/DeepSeek-R1
[36m(vllm-benchmark, pid=7329)[0m ++ echo sharegpt
[36m(vllm-benchmark, pid=7329)[0m ++ cut -d, -f1
[36m(vllm-benchmark, pid=7329)[0m + INPUT_LEN=sharegpt
[36m(vllm-benchmark, pid=7329)[0m ++ echo sharegpt
[36m(vllm-benchmark, pid=7329)[0m ++ cut -d, -f2
[36m(vllm-benchmark, pid=7329)[0m + OUTPUT_LEN=sharegpt
[36m(vllm-benchmark, pid=7329)[0m + [[ '' == \s\g\l ]]
[36m(vllm-benchmark, pid=7329)[0m + [[ sharegpt == \s\h\a\r\e\g\p\t ]]
[36m(vllm-benchmark, pid=7329)[0m + uv run --with-requirements requirements-benchmark.txt vllm-benchmarks/benchmarks/benchmark_serving.py --model deepseek-ai/DeepSeek-R1 --dataset-name sharegpt --ignore-eos --dataset-path vllm-benchmarks/benchmarks/sharegpt.json --num-prompts 500 --request-rate 10 --save-result --result-dir results/deepseek-r1 --result-filename sgl-sharegpt-.json
[36m(vllm-benchmark, pid=7329)[0m INFO 04-20 01:43:57 [__init__.py:239] Automatically detected platform cuda.
[36m(vllm-benchmark, pid=7329)[0m Namespace(backend='vllm', base_url=None, host='127.0.0.1', port=8000, endpoint='/v1/completions', dataset_name='sharegpt', dataset_path='vllm-benchmarks/benchmarks/sharegpt.json', max_concurrency=None, model='deepseek-ai/DeepSeek-R1', tokenizer=None, use_beam_search=False, num_prompts=500, logprobs=None, request_rate=10.0, burstiness=1.0, seed=0, trust_remote_code=False, disable_tqdm=False, profile=False, save_result=True, save_detailed=False, metadata=None, result_dir='results/deepseek-r1', result_filename='sgl-sharegpt-.json', ignore_eos=True, percentile_metrics='ttft,tpot,itl', metric_percentiles='99', goodput=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, sharegpt_output_len=None, random_input_len=1024, random_output_len=128, random_range_ratio=0.0, random_prefix_len=0, hf_subset=None, hf_split=None, hf_output_len=None, top_p=None, top_k=None, min_p=None, temperature=None, tokenizer_mode='auto', served_model_name=None, lora_modules=None)
[36m(vllm-benchmark, pid=7329)[0m Starting initial single prompt test run...
[36m(vllm-benchmark, pid=7329)[0m Initial test run completed. Starting main benchmark run...
[36m(vllm-benchmark, pid=7329)[0m Traffic request rate: 10.0
[36m(vllm-benchmark, pid=7329)[0m Burstiness factor: 1.0 (Poisson process)
[36m(vllm-benchmark, pid=7329)[0m Maximum request concurrency: None
[36m(vllm-benchmark, pid=7329)[0m 
[36m(vllm-benchmark, pid=7329)[0m   0%|          | 0/500 [00:00<?, ?it/s]
[36m(vllm-benchmark, pid=7329)[0m   0%|          | 1/500 [00:38<5:16:25, 38.05s/it]
[36m(vllm-benchmark, pid=7329)[0m   0%|          | 2/500 [00:38<2:14:31, 16.21s/it]
[36m(vllm-benchmark, pid=7329)[0m   1%|          | 5/500 [00:39<38:34,  4.68s/it]  
[36m(vllm-benchmark, pid=7329)[0m   2%|▏         | 8/500 [00:39<19:32,  2.38s/it]
[36m(vllm-benchmark, pid=7329)[0m   2%|▏         | 11/500 [00:39<11:34,  1.42s/it]
[36m(vllm-benchmark, pid=7329)[0m   2%|▏         | 12/500 [00:40<09:49,  1.21s/it]
[36m(vllm-benchmark, pid=7329)[0m   3%|▎         | 17/500 [00:40<04:53,  1.65it/s]
[36m(vllm-benchmark, pid=7329)[0m   5%|▍         | 23/500 [00:40<02:36,  3.04it/s]
[36m(vllm-benchmark, pid=7329)[0m   5%|▌         | 27/500 [00:41<01:59,  3.95it/s]
[36m(vllm-benchmark, pid=7329)[0m   7%|▋         | 34/500 [00:48<04:52,  1.59it/s]
[36m(vllm-benchmark, pid=7329)[0m   8%|▊         | 39/500 [00:49<03:42,  2.07it/s]
[36m(vllm-benchmark, pid=7329)[0m   9%|▉         | 44/500 [01:11<12:39,  1.67s/it]
[36m(vllm-benchmark, pid=7329)[0m  11%|█         | 55/500 [01:11<06:22,  1.16it/s]
[36m(vllm-benchmark, pid=7329)[0m  11%|█▏        | 57/500 [01:18<08:38,  1.17s/it]
[36m(vllm-benchmark, pid=7329)[0m  12%|█▏        | 59/500 [01:19<07:29,  1.02s/it]
[36m(vllm-benchmark, pid=7329)[0m  12%|█▏        | 61/500 [01:19<06:18,  1.16it/s]
[36m(vllm-benchmark, pid=7329)[0m  15%|█▍        | 74/500 [01:19<02:28,  2.87it/s]
[36m(vllm-benchmark, pid=7329)[0m  16%|█▌        | 78/500 [01:19<01:59,  3.53it/s]
[36m(vllm-benchmark, pid=7329)[0m  16%|█▌        | 81/500 [01:19<01:40,  4.16it/s]
[36m(vllm-benchmark, pid=7329)[0m  17%|█▋        | 84/500 [01:19<01:23,  4.97it/s]
[36m(vllm-benchmark, pid=7329)[0m  19%|█▉        | 95/500 [01:19<00:42,  9.57it/s]
[36m(vllm-benchmark, pid=7329)[0m  20%|██        | 100/500 [01:20<00:34, 11.61it/s]
[36m(vllm-benchmark, pid=7329)[0m  21%|██        | 106/500 [01:20<00:27, 14.52it/s]
[36m(vllm-benchmark, pid=7329)[0m  22%|██▏       | 110/500 [01:20<00:24, 16.01it/s]
[36m(vllm-benchmark, pid=7329)[0m  23%|██▎       | 114/500 [01:20<00:21, 17.66it/s]
[36m(vllm-benchmark, pid=7329)[0m  24%|██▍       | 121/500 [01:20<00:20, 18.92it/s]
[36m(vllm-benchmark, pid=7329)[0m  25%|██▌       | 127/500 [01:21<00:19, 18.71it/s]
[36m(vllm-benchmark, pid=7329)[0m  26%|██▋       | 132/500 [01:21<00:17, 20.89it/s]
[36m(vllm-benchmark, pid=7329)[0m  27%|██▋       | 135/500 [01:21<00:17, 20.56it/s]
[36m(vllm-benchmark, pid=7329)[0m  28%|██▊       | 139/500 [01:21<00:16, 21.37it/s]
[36m(vllm-benchmark, pid=7329)[0m  28%|██▊       | 142/500 [01:21<00:17, 20.42it/s]
[36m(vllm-benchmark, pid=7329)[0m  29%|██▉       | 146/500 [01:22<00:20, 17.48it/s]
[36m(vllm-benchmark, pid=7329)[0m  30%|██▉       | 148/500 [01:22<00:26, 13.10it/s]
[36m(vllm-benchmark, pid=7329)[0m  30%|███       | 152/500 [01:22<00:22, 15.43it/s]
[36m(vllm-benchmark, pid=7329)[0m  31%|███       | 154/500 [01:22<00:24, 14.35it/s]
[36m(vllm-benchmark, pid=7329)[0m  31%|███       | 156/500 [01:23<00:24, 13.92it/s]
[36m(vllm-benchmark, pid=7329)[0m  32%|███▏      | 158/500 [01:23<00:31, 10.85it/s]
[36m(vllm-benchmark, pid=7329)[0m  32%|███▏      | 160/500 [01:23<00:37,  8.95it/s]
[36m(vllm-benchmark, pid=7329)[0m  32%|███▏      | 162/500 [01:23<00:34,  9.70it/s]
[36m(vllm-benchmark, pid=7329)[0m  33%|███▎      | 164/500 [01:24<00:32, 10.34it/s]
[36m(vllm-benchmark, pid=7329)[0m  33%|███▎      | 166/500 [01:24<00:30, 10.79it/s]
[36m(vllm-benchmark, pid=7329)[0m  34%|███▎      | 168/500 [01:24<00:37,  8.82it/s]
[36m(vllm-benchmark, pid=7329)[0m  34%|███▍      | 170/500 [01:24<00:34,  9.55it/s]
[36m(vllm-benchmark, pid=7329)[0m  34%|███▍      | 172/500 [01:25<00:46,  7.12it/s]
[36m(vllm-benchmark, pid=7329)[0m  35%|███▍      | 174/500 [01:25<00:48,  6.68it/s]
[36m(vllm-benchmark, pid=7329)[0m  35%|███▌      | 177/500 [01:26<00:49,  6.50it/s]
[36m(vllm-benchmark, pid=7329)[0m  36%|███▌      | 181/500 [01:26<00:34,  9.14it/s]
[36m(vllm-benchmark, pid=7329)[0m  37%|███▋      | 183/500 [01:26<00:44,  7.13it/s]
[36m(vllm-benchmark, pid=7329)[0m  37%|███▋      | 184/500 [01:27<01:07,  4.71it/s]
[36m(vllm-benchmark, pid=7329)[0m  37%|███▋      | 186/500 [01:28<01:39,  3.16it/s]
[36m(vllm-benchmark, pid=7329)[0m  37%|███▋      | 187/500 [01:28<01:30,  3.45it/s]
[36m(vllm-benchmark, pid=7329)[0m  38%|███▊      | 190/500 [01:28<00:58,  5.27it/s]
[36m(vllm-benchmark, pid=7329)[0m  38%|███▊      | 192/500 [01:29<01:03,  4.84it/s]
[36m(vllm-benchmark, pid=7329)[0m  39%|███▉      | 194/500 [01:29<01:05,  4.66it/s]
[36m(vllm-benchmark, pid=7329)[0m  39%|███▉      | 195/500 [01:30<01:20,  3.78it/s]
[36m(vllm-benchmark, pid=7329)[0m  39%|███▉      | 197/500 [01:30<01:25,  3.55it/s]
[36m(vllm-benchmark, pid=7329)[0m  40%|███▉      | 198/500 [01:31<01:27,  3.45it/s]
[36m(vllm-benchmark, pid=7329)[0m  40%|████      | 200/500 [01:32<01:39,  3.02it/s]
[36m(vllm-benchmark, pid=7329)[0m  40%|████      | 201/500 [01:32<01:50,  2.71it/s]
[36m(vllm-benchmark, pid=7329)[0m  40%|████      | 202/500 [01:32<01:47,  2.78it/s]
[36m(vllm-benchmark, pid=7329)[0m  41%|████      | 203/500 [01:33<01:54,  2.59it/s]
[36m(vllm-benchmark, pid=7329)[0m  41%|████      | 204/500 [01:33<01:37,  3.03it/s]
[36m(vllm-benchmark, pid=7329)[0m  41%|████      | 206/500 [01:34<01:38,  2.99it/s]
[36m(vllm-benchmark, pid=7329)[0m  41%|████▏     | 207/500 [01:34<01:35,  3.07it/s]
[36m(vllm-benchmark, pid=7329)[0m  42%|████▏     | 209/500 [01:34<01:08,  4.28it/s]
[36m(vllm-benchmark, pid=7329)[0m  42%|████▏     | 210/500 [01:34<01:02,  4.64it/s]
[36m(vllm-benchmark, pid=7329)[0m  42%|████▏     | 211/500 [01:34<00:58,  4.98it/s]
[36m(vllm-benchmark, pid=7329)[0m  43%|████▎     | 214/500 [01:35<00:51,  5.57it/s]
[36m(vllm-benchmark, pid=7329)[0m  43%|████▎     | 215/500 [01:35<00:52,  5.47it/s]
[36m(vllm-benchmark, pid=7329)[0m  43%|████▎     | 216/500 [01:35<01:00,  4.68it/s]
[36m(vllm-benchmark, pid=7329)[0m  44%|████▎     | 218/500 [01:36<00:46,  6.13it/s]
[36m(vllm-benchmark, pid=7329)[0m  44%|████▍     | 219/500 [01:36<01:06,  4.25it/s]
[36m(vllm-benchmark, pid=7329)[0m  44%|████▍     | 221/500 [01:36<00:58,  4.77it/s]
[36m(vllm-benchmark, pid=7329)[0m  44%|████▍     | 222/500 [01:37<01:05,  4.27it/s]
[36m(vllm-benchmark, pid=7329)[0m  45%|████▍     | 224/500 [01:37<01:14,  3.71it/s]
[36m(vllm-benchmark, pid=7329)[0m  45%|████▌     | 225/500 [01:38<01:08,  4.04it/s]
[36m(vllm-benchmark, pid=7329)[0m  45%|████▌     | 226/500 [01:38<01:22,  3.32it/s]
[36m(vllm-benchmark, pid=7329)[0m  45%|████▌     | 227/500 [01:38<01:23,  3.26it/s]
[36m(vllm-benchmark, pid=7329)[0m  46%|████▌     | 228/500 [01:39<01:25,  3.17it/s]
[36m(vllm-benchmark, pid=7329)[0m  46%|████▌     | 229/500 [01:39<01:35,  2.83it/s]
[36m(vllm-benchmark, pid=7329)[0m  46%|████▌     | 230/500 [01:39<01:22,  3.26it/s]
[36m(vllm-benchmark, pid=7329)[0m  46%|████▋     | 232/500 [01:40<01:05,  4.10it/s]
[36m(vllm-benchmark, pid=7329)[0m  47%|████▋     | 233/500 [01:40<00:59,  4.47it/s]
[36m(vllm-benchmark, pid=7329)[0m  47%|████▋     | 234/500 [01:40<01:06,  3.99it/s]
[36m(vllm-benchmark, pid=7329)[0m  47%|████▋     | 235/500 [01:40<00:59,  4.43it/s]
[36m(vllm-benchmark, pid=7329)[0m  47%|████▋     | 236/500 [01:41<01:07,  3.92it/s]
[36m(vllm-benchmark, pid=7329)[0m  47%|████▋     | 237/500 [01:41<01:00,  4.32it/s]
[36m(vllm-benchmark, pid=7329)[0m  48%|████▊     | 238/500 [01:41<01:19,  3.28it/s]
[36m(vllm-benchmark, pid=7329)[0m  48%|████▊     | 239/500 [01:42<01:21,  3.21it/s]
[36m(vllm-benchmark, pid=7329)[0m  48%|████▊     | 240/500 [01:42<01:21,  3.21it/s]
[36m(vllm-benchmark, pid=7329)[0m  48%|████▊     | 241/500 [01:42<01:09,  3.73it/s]
[36m(vllm-benchmark, pid=7329)[0m  48%|████▊     | 242/500 [01:43<01:14,  3.47it/s]
[36m(vllm-benchmark, pid=7329)[0m  49%|████▊     | 243/500 [01:43<01:03,  4.04it/s]
[36m(vllm-benchmark, pid=7329)[0m  49%|████▉     | 244/500 [01:43<01:09,  3.71it/s]
[36m(vllm-benchmark, pid=7329)[0m  49%|████▉     | 245/500 [01:43<01:20,  3.18it/s]
[36m(vllm-benchmark, pid=7329)[0m  49%|████▉     | 246/500 [01:44<01:31,  2.79it/s]
[36m(vllm-benchmark, pid=7329)[0m  50%|████▉     | 248/500 [01:44<00:59,  4.20it/s]
[36m(vllm-benchmark, pid=7329)[0m  50%|████▉     | 249/500 [01:44<00:54,  4.64it/s]
[36m(vllm-benchmark, pid=7329)[0m  50%|█████     | 252/500 [01:45<00:48,  5.16it/s]
[36m(vllm-benchmark, pid=7329)[0m  51%|█████     | 253/500 [01:45<00:54,  4.54it/s]
[36m(vllm-benchmark, pid=7329)[0m  51%|█████     | 254/500 [01:45<00:50,  4.85it/s]
[36m(vllm-benchmark, pid=7329)[0m  51%|█████     | 255/500 [01:45<00:48,  5.10it/s]
[36m(vllm-benchmark, pid=7329)[0m  51%|█████     | 256/500 [01:46<01:15,  3.24it/s]
[36m(vllm-benchmark, pid=7329)[0m  51%|█████▏    | 257/500 [01:46<01:06,  3.64it/s]
[36m(vllm-benchmark, pid=7329)[0m  52%|█████▏    | 258/500 [01:46<00:57,  4.18it/s]
[36m(vllm-benchmark, pid=7329)[0m  52%|█████▏    | 260/500 [01:47<00:48,  4.91it/s]
[36m(vllm-benchmark, pid=7329)[0m  52%|█████▏    | 262/500 [01:47<00:38,  6.12it/s]
[36m(vllm-benchmark, pid=7329)[0m  53%|█████▎    | 264/500 [01:47<00:38,  6.10it/s]
[36m(vllm-benchmark, pid=7329)[0m  53%|█████▎    | 265/500 [01:47<00:38,  6.07it/s]
[36m(vllm-benchmark, pid=7329)[0m  53%|█████▎    | 266/500 [01:48<00:37,  6.17it/s]
[36m(vllm-benchmark, pid=7329)[0m  54%|█████▎    | 268/500 [01:48<00:52,  4.41it/s]
[36m(vllm-benchmark, pid=7329)[0m  54%|█████▍    | 269/500 [01:48<00:50,  4.61it/s]
[36m(vllm-benchmark, pid=7329)[0m  54%|█████▍    | 271/500 [01:49<00:37,  6.06it/s]
[36m(vllm-benchmark, pid=7329)[0m  54%|█████▍    | 272/500 [01:49<00:37,  6.07it/s]
[36m(vllm-benchmark, pid=7329)[0m  55%|█████▌    | 275/500 [01:49<00:36,  6.18it/s]
[36m(vllm-benchmark, pid=7329)[0m  55%|█████▌    | 277/500 [01:49<00:31,  7.13it/s]
[36m(vllm-benchmark, pid=7329)[0m  56%|█████▌    | 278/500 [01:50<00:57,  3.85it/s]
[36m(vllm-benchmark, pid=7329)[0m  56%|█████▌    | 279/500 [01:50<01:01,  3.58it/s]
[36m(vllm-benchmark, pid=7329)[0m  56%|█████▌    | 280/500 [01:51<00:55,  3.96it/s]
[36m(vllm-benchmark, pid=7329)[0m  56%|█████▌    | 281/500 [01:51<00:50,  4.34it/s]
[36m(vllm-benchmark, pid=7329)[0m  56%|█████▋    | 282/500 [01:51<01:04,  3.40it/s]
[36m(vllm-benchmark, pid=7329)[0m  57%|█████▋    | 283/500 [01:51<00:57,  3.78it/s]
[36m(vllm-benchmark, pid=7329)[0m  57%|█████▋    | 284/500 [01:52<00:59,  3.66it/s]
[36m(vllm-benchmark, pid=7329)[0m  57%|█████▋    | 287/500 [01:52<00:40,  5.28it/s]
[36m(vllm-benchmark, pid=7329)[0m  58%|█████▊    | 289/500 [01:52<00:38,  5.42it/s]
[36m(vllm-benchmark, pid=7329)[0m  58%|█████▊    | 291/500 [01:53<00:31,  6.61it/s]
[36m(vllm-benchmark, pid=7329)[0m  58%|█████▊    | 292/500 [01:54<01:04,  3.21it/s]
[36m(vllm-benchmark, pid=7329)[0m  59%|█████▊    | 293/500 [01:54<01:12,  2.86it/s]
[36m(vllm-benchmark, pid=7329)[0m  59%|█████▉    | 297/500 [01:55<00:49,  4.11it/s]
[36m(vllm-benchmark, pid=7329)[0m  60%|█████▉    | 299/500 [01:55<00:44,  4.51it/s]
[36m(vllm-benchmark, pid=7329)[0m  61%|██████    | 303/500 [01:55<00:28,  6.87it/s]
[36m(vllm-benchmark, pid=7329)[0m  61%|██████    | 305/500 [01:56<00:29,  6.63it/s]
[36m(vllm-benchmark, pid=7329)[0m  61%|██████    | 306/500 [01:56<00:38,  4.98it/s]
[36m(vllm-benchmark, pid=7329)[0m  62%|██████▏   | 308/500 [01:56<00:32,  5.99it/s]
[36m(vllm-benchmark, pid=7329)[0m  62%|██████▏   | 309/500 [01:57<00:36,  5.23it/s]
[36m(vllm-benchmark, pid=7329)[0m  62%|██████▏   | 310/500 [01:57<00:42,  4.47it/s]
[36m(vllm-benchmark, pid=7329)[0m  62%|██████▏   | 311/500 [01:57<00:47,  4.00it/s]
[36m(vllm-benchmark, pid=7329)[0m  63%|██████▎   | 313/500 [01:58<00:40,  4.58it/s]
[36m(vllm-benchmark, pid=7329)[0m  63%|██████▎   | 314/500 [01:58<00:51,  3.61it/s]
[36m(vllm-benchmark, pid=7329)[0m  63%|██████▎   | 315/500 [01:59<01:01,  3.03it/s]
[36m(vllm-benchmark, pid=7329)[0m  63%|██████▎   | 317/500 [01:59<00:47,  3.89it/s]
[36m(vllm-benchmark, pid=7329)[0m  64%|██████▍   | 320/500 [01:59<00:39,  4.57it/s]
[36m(vllm-benchmark, pid=7329)[0m  64%|██████▍   | 321/500 [02:00<01:03,  2.83it/s]
[36m(vllm-benchmark, pid=7329)[0m  64%|██████▍   | 322/500 [02:01<00:56,  3.18it/s]
[36m(vllm-benchmark, pid=7329)[0m  65%|██████▍   | 323/500 [02:01<00:55,  3.18it/s]
[36m(vllm-benchmark, pid=7329)[0m  65%|██████▌   | 325/500 [02:01<00:45,  3.85it/s]
[36m(vllm-benchmark, pid=7329)[0m  65%|██████▌   | 326/500 [02:02<00:53,  3.28it/s]
[36m(vllm-benchmark, pid=7329)[0m  66%|██████▌   | 329/500 [02:02<00:45,  3.76it/s]
[36m(vllm-benchmark, pid=7329)[0m  66%|██████▌   | 330/500 [02:03<00:41,  4.05it/s]
[36m(vllm-benchmark, pid=7329)[0m  66%|██████▌   | 331/500 [02:03<00:56,  3.00it/s]
[36m(vllm-benchmark, pid=7329)[0m  66%|██████▋   | 332/500 [02:03<00:49,  3.41it/s]
[36m(vllm-benchmark, pid=7329)[0m  67%|██████▋   | 334/500 [02:04<00:39,  4.20it/s]
[36m(vllm-benchmark, pid=7329)[0m  67%|██████▋   | 336/500 [02:04<00:29,  5.52it/s]
[36m(vllm-benchmark, pid=7329)[0m  67%|██████▋   | 337/500 [02:04<00:29,  5.51it/s]
[36m(vllm-benchmark, pid=7329)[0m  68%|██████▊   | 338/500 [02:04<00:28,  5.76it/s]
[36m(vllm-benchmark, pid=7329)[0m  68%|██████▊   | 339/500 [02:04<00:28,  5.72it/s]
[36m(vllm-benchmark, pid=7329)[0m  68%|██████▊   | 340/500 [02:05<00:34,  4.70it/s]
[36m(vllm-benchmark, pid=7329)[0m  68%|██████▊   | 342/500 [02:05<00:27,  5.77it/s]
[36m(vllm-benchmark, pid=7329)[0m  69%|██████▊   | 343/500 [02:05<00:28,  5.43it/s]
[36m(vllm-benchmark, pid=7329)[0m  70%|██████▉   | 348/500 [02:05<00:14, 10.37it/s]
[36m(vllm-benchmark, pid=7329)[0m  70%|███████   | 350/500 [02:05<00:13, 11.07it/s]
[36m(vllm-benchmark, pid=7329)[0m  70%|███████   | 352/500 [02:06<00:18,  7.99it/s]
[36m(vllm-benchmark, pid=7329)[0m  71%|███████   | 355/500 [02:06<00:15,  9.46it/s]
[36m(vllm-benchmark, pid=7329)[0m  71%|███████▏  | 357/500 [02:07<00:17,  8.01it/s]
[36m(vllm-benchmark, pid=7329)[0m  72%|███████▏  | 361/500 [02:07<00:12, 11.44it/s]
[36m(vllm-benchmark, pid=7329)[0m  73%|███████▎  | 363/500 [02:07<00:11, 11.96it/s]
[36m(vllm-benchmark, pid=7329)[0m  73%|███████▎  | 365/500 [02:07<00:14,  9.27it/s]
[36m(vllm-benchmark, pid=7329)[0m  73%|███████▎  | 367/500 [02:07<00:15,  8.54it/s]
[36m(vllm-benchmark, pid=7329)[0m  74%|███████▍  | 369/500 [02:08<00:13,  9.57it/s]
[36m(vllm-benchmark, pid=7329)[0m  75%|███████▍  | 373/500 [02:08<00:09, 13.26it/s]
[36m(vllm-benchmark, pid=7329)[0m  75%|███████▌  | 375/500 [02:08<00:09, 12.53it/s]
[36m(vllm-benchmark, pid=7329)[0m  75%|███████▌  | 377/500 [02:09<00:16,  7.42it/s]
[36m(vllm-benchmark, pid=7329)[0m  76%|███████▌  | 380/500 [02:09<00:12,  9.76it/s]
[36m(vllm-benchmark, pid=7329)[0m  76%|███████▋  | 382/500 [02:09<00:10, 10.75it/s]
[36m(vllm-benchmark, pid=7329)[0m  77%|███████▋  | 387/500 [02:09<00:08, 13.59it/s]
[36m(vllm-benchmark, pid=7329)[0m  78%|███████▊  | 389/500 [02:09<00:08, 13.72it/s]
[36m(vllm-benchmark, pid=7329)[0m  78%|███████▊  | 391/500 [02:09<00:09, 11.83it/s]
[36m(vllm-benchmark, pid=7329)[0m  79%|███████▊  | 393/500 [02:10<00:11,  9.68it/s]
[36m(vllm-benchmark, pid=7329)[0m  79%|███████▉  | 395/500 [02:10<00:10,  9.88it/s]
[36m(vllm-benchmark, pid=7329)[0m  79%|███████▉  | 397/500 [02:10<00:09, 10.82it/s]
[36m(vllm-benchmark, pid=7329)[0m  80%|███████▉  | 399/500 [02:10<00:10,  9.92it/s]
[36m(vllm-benchmark, pid=7329)[0m  80%|████████  | 401/500 [02:11<00:16,  6.16it/s]
[36m(vllm-benchmark, pid=7329)[0m  81%|████████  | 404/500 [02:11<00:11,  8.02it/s]
[36m(vllm-benchmark, pid=7329)[0m  81%|████████▏ | 407/500 [02:11<00:08, 10.50it/s]
[36m(vllm-benchmark, pid=7329)[0m  82%|████████▏ | 409/500 [02:12<00:09,  9.70it/s]
[36m(vllm-benchmark, pid=7329)[0m  82%|████████▏ | 411/500 [02:12<00:08, 10.83it/s]
[36m(vllm-benchmark, pid=7329)[0m  83%|████████▎ | 413/500 [02:12<00:09,  9.19it/s]
[36m(vllm-benchmark, pid=7329)[0m  83%|████████▎ | 415/500 [02:12<00:08,  9.58it/s]
[36m(vllm-benchmark, pid=7329)[0m  83%|████████▎ | 417/500 [02:12<00:10,  7.90it/s]
[36m(vllm-benchmark, pid=7329)[0m  84%|████████▍ | 420/500 [02:13<00:09,  8.56it/s]
[36m(vllm-benchmark, pid=7329)[0m  84%|████████▍ | 421/500 [02:13<00:10,  7.37it/s]
[36m(vllm-benchmark, pid=7329)[0m  84%|████████▍ | 422/500 [02:13<00:11,  6.96it/s]
[36m(vllm-benchmark, pid=7329)[0m  85%|████████▍ | 423/500 [02:13<00:11,  6.62it/s]
[36m(vllm-benchmark, pid=7329)[0m  85%|████████▌ | 425/500 [02:14<00:10,  7.18it/s]
[36m(vllm-benchmark, pid=7329)[0m  85%|████████▌ | 426/500 [02:14<00:09,  7.41it/s]
[36m(vllm-benchmark, pid=7329)[0m  86%|████████▌ | 428/500 [02:14<00:14,  5.12it/s]
[36m(vllm-benchmark, pid=7329)[0m  86%|████████▌ | 429/500 [02:15<00:15,  4.61it/s]
[36m(vllm-benchmark, pid=7329)[0m  86%|████████▌ | 430/500 [02:15<00:13,  5.16it/s]
[36m(vllm-benchmark, pid=7329)[0m  86%|████████▋ | 432/500 [02:15<00:10,  6.59it/s]
[36m(vllm-benchmark, pid=7329)[0m  87%|████████▋ | 433/500 [02:15<00:09,  6.95it/s]
[36m(vllm-benchmark, pid=7329)[0m  87%|████████▋ | 434/500 [02:15<00:12,  5.16it/s]
[36m(vllm-benchmark, pid=7329)[0m  87%|████████▋ | 435/500 [02:16<00:11,  5.74it/s]
[36m(vllm-benchmark, pid=7329)[0m  87%|████████▋ | 436/500 [02:16<00:18,  3.54it/s]
[36m(vllm-benchmark, pid=7329)[0m  87%|████████▋ | 437/500 [02:16<00:15,  3.98it/s]
[36m(vllm-benchmark, pid=7329)[0m  88%|████████▊ | 438/500 [02:16<00:14,  4.15it/s]
[36m(vllm-benchmark, pid=7329)[0m  88%|████████▊ | 440/500 [02:17<00:10,  5.89it/s]
[36m(vllm-benchmark, pid=7329)[0m  88%|████████▊ | 442/500 [02:17<00:08,  6.88it/s]
[36m(vllm-benchmark, pid=7329)[0m  89%|████████▉ | 444/500 [02:17<00:06,  8.92it/s]
[36m(vllm-benchmark, pid=7329)[0m  89%|████████▉ | 446/500 [02:17<00:08,  6.20it/s]
[36m(vllm-benchmark, pid=7329)[0m  90%|████████▉ | 448/500 [02:18<00:08,  6.31it/s]
[36m(vllm-benchmark, pid=7329)[0m  90%|█████████ | 450/500 [02:18<00:07,  7.13it/s]
[36m(vllm-benchmark, pid=7329)[0m  90%|█████████ | 451/500 [02:18<00:06,  7.03it/s]
[36m(vllm-benchmark, pid=7329)[0m  91%|█████████ | 453/500 [02:18<00:05,  8.43it/s]
[36m(vllm-benchmark, pid=7329)[0m  91%|█████████ | 455/500 [02:19<00:06,  6.94it/s]
[36m(vllm-benchmark, pid=7329)[0m  91%|█████████ | 456/500 [02:19<00:06,  6.93it/s]
[36m(vllm-benchmark, pid=7329)[0m  92%|█████████▏| 460/500 [02:19<00:05,  7.95it/s]
[36m(vllm-benchmark, pid=7329)[0m  92%|█████████▏| 461/500 [02:20<00:07,  5.53it/s]
[36m(vllm-benchmark, pid=7329)[0m  92%|█████████▏| 462/500 [02:20<00:07,  5.00it/s]
[36m(vllm-benchmark, pid=7329)[0m  93%|█████████▎| 463/500 [02:20<00:07,  5.06it/s]
[36m(vllm-benchmark, pid=7329)[0m  93%|█████████▎| 464/500 [02:20<00:07,  5.12it/s]
[36m(vllm-benchmark, pid=7329)[0m  93%|█████████▎| 465/500 [02:21<00:08,  3.98it/s]
[36m(vllm-benchmark, pid=7329)[0m  93%|█████████▎| 466/500 [02:21<00:08,  3.86it/s]
[36m(vllm-benchmark, pid=7329)[0m  94%|█████████▎| 468/500 [02:22<00:08,  3.63it/s]
[36m(vllm-benchmark, pid=7329)[0m  94%|█████████▍| 470/500 [02:22<00:08,  3.35it/s]
[36m(vllm-benchmark, pid=7329)[0m  94%|█████████▍| 471/500 [02:23<00:07,  3.80it/s]
[36m(vllm-benchmark, pid=7329)[0m  94%|█████████▍| 472/500 [02:23<00:07,  3.80it/s]
[36m(vllm-benchmark, pid=7329)[0m  95%|█████████▍| 473/500 [02:23<00:08,  3.04it/s]
[36m(vllm-benchmark, pid=7329)[0m  95%|█████████▍| 474/500 [02:24<00:08,  3.00it/s]
[36m(vllm-benchmark, pid=7329)[0m  95%|█████████▌| 475/500 [02:24<00:10,  2.39it/s]
[36m(vllm-benchmark, pid=7329)[0m  95%|█████████▌| 476/500 [02:25<00:10,  2.33it/s]
[36m(vllm-benchmark, pid=7329)[0m  95%|█████████▌| 477/500 [02:25<00:09,  2.31it/s]
[36m(vllm-benchmark, pid=7329)[0m  96%|█████████▌| 480/500 [02:25<00:04,  4.09it/s]
[36m(vllm-benchmark, pid=7329)[0m  96%|█████████▋| 482/500 [02:26<00:05,  3.02it/s]
[36m(vllm-benchmark, pid=7329)[0m  97%|█████████▋| 484/500 [02:27<00:03,  4.05it/s]
[36m(vllm-benchmark, pid=7329)[0m  97%|█████████▋| 485/500 [02:27<00:03,  4.25it/s]
[36m(vllm-benchmark, pid=7329)[0m  97%|█████████▋| 486/500 [02:27<00:04,  3.48it/s]
[36m(vllm-benchmark, pid=7329)[0m  97%|█████████▋| 487/500 [02:28<00:04,  2.87it/s]
[36m(vllm-benchmark, pid=7329)[0m  98%|█████████▊| 488/500 [02:28<00:03,  3.46it/s]
[36m(vllm-benchmark, pid=7329)[0m  98%|█████████▊| 489/500 [02:28<00:03,  3.35it/s]
[36m(vllm-benchmark, pid=7329)[0m  98%|█████████▊| 490/500 [02:29<00:04,  2.27it/s]
[36m(vllm-benchmark, pid=7329)[0m  99%|█████████▊| 493/500 [02:29<00:01,  4.50it/s]
[36m(vllm-benchmark, pid=7329)[0m  99%|█████████▉| 495/500 [02:30<00:01,  3.30it/s]
[36m(vllm-benchmark, pid=7329)[0m  99%|█████████▉| 497/500 [02:30<00:00,  4.20it/s]
[36m(vllm-benchmark, pid=7329)[0m 100%|█████████▉| 498/500 [02:30<00:00,  4.61it/s]
100%|██████████| 500/500 [02:31<00:00,  4.55it/s]
100%|██████████| 500/500 [02:31<00:00,  3.30it/s]
[36m(vllm-benchmark, pid=7329)[0m ============ Serving Benchmark Result ============
[36m(vllm-benchmark, pid=7329)[0m Successful requests:                     500       
[36m(vllm-benchmark, pid=7329)[0m Benchmark duration (s):                  151.38    
[36m(vllm-benchmark, pid=7329)[0m Total input tokens:                      102975    
[36m(vllm-benchmark, pid=7329)[0m Total generated tokens:                  107666    
[36m(vllm-benchmark, pid=7329)[0m Request throughput (req/s):              3.30      
[36m(vllm-benchmark, pid=7329)[0m Output token throughput (tok/s):         711.23    
[36m(vllm-benchmark, pid=7329)[0m Total Token throughput (tok/s):          1391.47   
[36m(vllm-benchmark, pid=7329)[0m ---------------Time to First Token----------------
[36m(vllm-benchmark, pid=7329)[0m Mean TTFT (ms):                          7575.76   
[36m(vllm-benchmark, pid=7329)[0m Median TTFT (ms):                        6933.50   
[36m(vllm-benchmark, pid=7329)[0m P99 TTFT (ms):                           28112.72  
[36m(vllm-benchmark, pid=7329)[0m -----Time per Output Token (excl. 1st token)------
[36m(vllm-benchmark, pid=7329)[0m Mean TPOT (ms):                          1057.06   
[36m(vllm-benchmark, pid=7329)[0m Median TPOT (ms):                        401.49    
[36m(vllm-benchmark, pid=7329)[0m P99 TPOT (ms):                           7344.32   
[36m(vllm-benchmark, pid=7329)[0m ---------------Inter-token Latency----------------
[36m(vllm-benchmark, pid=7329)[0m Mean ITL (ms):                           328.83    
[36m(vllm-benchmark, pid=7329)[0m Median ITL (ms):                         160.63    
[36m(vllm-benchmark, pid=7329)[0m P99 ITL (ms):                            7666.76   
[36m(vllm-benchmark, pid=7329)[0m ==================================================
[36m(vllm-benchmark, pid=7329)[0m + sleep 6
[36m(vllm-benchmark, pid=7329)[0m uv run --with rich --with pandas extract-result.py results/deepseek-r1
[36m(vllm-benchmark, pid=7329)[0m 
[36m(vllm-benchmark, pid=7329)[0m Loading results from /home/ubuntu/vLLM-Benchmark/results/deepseek-r1
[36m(vllm-benchmark, pid=7329)[0m Found 10 JSON files
[36m(vllm-benchmark, pid=7329)[0m Processing sgl-1000-2000-.json
[36m(vllm-benchmark, pid=7329)[0m Processing vllm-30000-100-.json
[36m(vllm-benchmark, pid=7329)[0m Processing vllm-sharegpt-.json
[36m(vllm-benchmark, pid=7329)[0m Processing vllm-10000-500-.json
[36m(vllm-benchmark, pid=7329)[0m Processing sgl-sharegpt-.json
[36m(vllm-benchmark, pid=7329)[0m Processing sgl-5000-1000-.json
[36m(vllm-benchmark, pid=7329)[0m Processing vllm-5000-1000-.json
[36m(vllm-benchmark, pid=7329)[0m Processing vllm-1000-2000-.json
[36m(vllm-benchmark, pid=7329)[0m Processing sgl-30000-100-.json
[36m(vllm-benchmark, pid=7329)[0m Processing sgl-10000-500-.json
[36m(vllm-benchmark, pid=7329)[0m Successfully loaded data with columns: ['backend', 'input_tokens', 
[36m(vllm-benchmark, pid=7329)[0m 'output_tokens', 'output_toks/s']
[36m(vllm-benchmark, pid=7329)[0m 
[36m(vllm-benchmark, pid=7329)[0m Data Preview:
[36m(vllm-benchmark, pid=7329)[0m   backend input_tokens output_tokens  output_toks/s
[36m(vllm-benchmark, pid=7329)[0m 0     sgl         1000          2000     976.676077
[36m(vllm-benchmark, pid=7329)[0m 1    vllm        30000           100      37.030036
[36m(vllm-benchmark, pid=7329)[0m 2    vllm     sharegpt      sharegpt    1323.743725
[36m(vllm-benchmark, pid=7329)[0m 3    vllm        10000           500     440.847598
[36m(vllm-benchmark, pid=7329)[0m 4     sgl     sharegpt      sharegpt     711.229440
[36m(vllm-benchmark, pid=7329)[0m 5     sgl         5000          1000     796.408890
[36m(vllm-benchmark, pid=7329)[0m 6    vllm         5000          1000     846.071516
[36m(vllm-benchmark, pid=7329)[0m 7    vllm         1000          2000    1124.662662
[36m(vllm-benchmark, pid=7329)[0m 8     sgl        30000           100      34.074778
[36m(vllm-benchmark, pid=7329)[0m 9     sgl        10000           500     379.359342
[36m(vllm-benchmark, pid=7329)[0m 
[36m(vllm-benchmark, pid=7329)[0m   input_tokens output_tokens  ...  gap_vllm_to_sgl_output_toks/s  vllm_output_toks/s
[36m(vllm-benchmark, pid=7329)[0m 0         1000          2000  ...                      15.152064         1124.662662
[36m(vllm-benchmark, pid=7329)[0m 1         5000          1000  ...                       6.235820          846.071516
[36m(vllm-benchmark, pid=7329)[0m 2        10000           500  ...                      16.208447          440.847598
[36m(vllm-benchmark, pid=7329)[0m 3        30000           100  ...                       8.672860           37.030036
[36m(vllm-benchmark, pid=7329)[0m 4     sharegpt      sharegpt  ...                      86.120491         1323.743725
[36m(vllm-benchmark, pid=7329)[0m 
[36m(vllm-benchmark, pid=7329)[0m [5 rows x 5 columns]
[36m(vllm-benchmark, pid=7329)[0m           Benchmark Comparison for vLLM (Output Tokens/s)           
[36m(vllm-benchmark, pid=7329)[0m ┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━━━━━┓
[36m(vllm-benchmark, pid=7329)[0m ┃ Input Tokens ┃ Output Tokens ┃    vLLM ┃    SGL ┃ vLLM/SGL Gap % ┃
[36m(vllm-benchmark, pid=7329)[0m ┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━━━━━┩
[36m(vllm-benchmark, pid=7329)[0m │         1000 │          2000 │ 1124.66 │ 976.68 │        +15.15% │
[36m(vllm-benchmark, pid=7329)[0m │         5000 │          1000 │  846.07 │ 796.41 │         +6.24% │
[36m(vllm-benchmark, pid=7329)[0m │        10000 │           500 │  440.85 │ 379.36 │        +16.21% │
[36m(vllm-benchmark, pid=7329)[0m │        30000 │           100 │   37.03 │  34.07 │         +8.67% │
[36m(vllm-benchmark, pid=7329)[0m │     sharegpt │      sharegpt │ 1323.74 │ 711.23 │        +86.12% │
[36m(vllm-benchmark, pid=7329)[0m └──────────────┴───────────────┴─────────┴────────┴────────────────┘
[36m(vllm-benchmark, pid=7329)[0m                          Model: deepseek-r1                         
[36m(vllm-benchmark, pid=7329)[0m ----- CSV for Easy Plotting -----
[36m(vllm-benchmark, pid=7329)[0m input_tokens,output_tokens,sgl_output_toks/s,gap_vllm_to_sgl_output_toks/s,vllm_
[36m(vllm-benchmark, pid=7329)[0m output_toks/s
[36m(vllm-benchmark, pid=7329)[0m 1000,2000,976.6760773653685,15.152064074514843,1124.6626624082273
[36m(vllm-benchmark, pid=7329)[0m 5000,1000,796.4088901065711,6.235820188168872,846.0715164562083
[36m(vllm-benchmark, pid=7329)[0m 10000,500,379.3593419529873,16.208446520936416,440.8475980156135
[36m(vllm-benchmark, pid=7329)[0m 30000,100,34.07477777738891,8.672860351693766,37.03003566917183
[36m(vllm-benchmark, pid=7329)[0m sharegpt,sharegpt,711.2294403080101,86.12049072805851,1323.7437245036924
[36m(vllm-benchmark, pid=7329)[0m 
[36m(vllm-benchmark, pid=7329)[0m + for pair in "1000,2000" "5000,1000" "10000,500" "30000,100" "sharegpt"
[36m(vllm-benchmark, pid=7329)[0m + '[' sgl == trt ']'
[36m(vllm-benchmark, pid=7329)[0m + just run-scenario sgl deepseek-r1 1000,2000
[36m(vllm-benchmark, pid=7329)[0m + just _ensure-results-dir deepseek-r1
[36m(vllm-benchmark, pid=7329)[0m mkdir -p results/deepseek-r1
[36m(vllm-benchmark, pid=7329)[0m + '[' sgl '!=' vllm ']'
[36m(vllm-benchmark, pid=7329)[0m + '[' sgl '!=' sgl ']'
[36m(vllm-benchmark, pid=7329)[0m ++ just _get-model-path deepseek-r1
[36m(vllm-benchmark, pid=7329)[0m + MODEL_PATH=deepseek-ai/DeepSeek-R1
[36m(vllm-benchmark, pid=7329)[0m ++ echo 1000,2000
[36m(vllm-benchmark, pid=7329)[0m ++ cut -d, -f1
[36m(vllm-benchmark, pid=7329)[0m + INPUT_LEN=1000
[36m(vllm-benchmark, pid=7329)[0m ++ echo 1000,2000
[36m(vllm-benchmark, pid=7329)[0m ++ cut -d, -f2
[36m(vllm-benchmark, pid=7329)[0m + OUTPUT_LEN=2000
[36m(vllm-benchmark, pid=7329)[0m + [[ '' == \s\g\l ]]
[36m(vllm-benchmark, pid=7329)[0m + [[ 1000,2000 == \s\h\a\r\e\g\p\t ]]
[36m(vllm-benchmark, pid=7329)[0m + uv run --with-requirements requirements-benchmark.txt vllm-benchmarks/benchmarks/benchmark_serving.py --model deepseek-ai/DeepSeek-R1 --dataset-name random --ignore-eos --num-prompts 50 --request-rate 10 --random-input-len 1000 --random-output-len 2000 --save-result --result-dir results/deepseek-r1 --result-filename sgl-1000-2000-.json
[36m(vllm-benchmark, pid=7329)[0m INFO 04-20 01:46:49 [__init__.py:239] Automatically detected platform cuda.
[36m(vllm-benchmark, pid=7329)[0m Namespace(backend='vllm', base_url=None, host='127.0.0.1', port=8000, endpoint='/v1/completions', dataset_name='random', dataset_path=None, max_concurrency=None, model='deepseek-ai/DeepSeek-R1', tokenizer=None, use_beam_search=False, num_prompts=50, logprobs=None, request_rate=10.0, burstiness=1.0, seed=0, trust_remote_code=False, disable_tqdm=False, profile=False, save_result=True, save_detailed=False, metadata=None, result_dir='results/deepseek-r1', result_filename='sgl-1000-2000-.json', ignore_eos=True, percentile_metrics='ttft,tpot,itl', metric_percentiles='99', goodput=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, sharegpt_output_len=None, random_input_len=1000, random_output_len=2000, random_range_ratio=0.0, random_prefix_len=0, hf_subset=None, hf_split=None, hf_output_len=None, top_p=None, top_k=None, min_p=None, temperature=None, tokenizer_mode='auto', served_model_name=None, lora_modules=None)
[36m(vllm-benchmark, pid=7329)[0m Starting initial single prompt test run...
[36m(vllm-benchmark, pid=7329)[0m Initial test run completed. Starting main benchmark run...
[36m(vllm-benchmark, pid=7329)[0m Traffic request rate: 10.0
[36m(vllm-benchmark, pid=7329)[0m Burstiness factor: 1.0 (Poisson process)
[36m(vllm-benchmark, pid=7329)[0m Maximum request concurrency: None
[36m(vllm-benchmark, pid=7329)[0m 
[36m(vllm-benchmark, pid=7329)[0m   0%|          | 0/50 [00:00<?, ?it/s]
[36m(vllm-benchmark, pid=7329)[0m   2%|▏         | 1/50 [01:42<1:23:51, 102.69s/it]
[36m(vllm-benchmark, pid=7329)[0m  12%|█▏        | 6/50 [01:42<09:15, 12.63s/it]   
 92%|█████████▏| 46/50 [01:42<00:04,  1.15s/it]
100%|██████████| 50/50 [01:42<00:00,  2.06s/it]
[36m(vllm-benchmark, pid=7329)[0m ============ Serving Benchmark Result ============
[36m(vllm-benchmark, pid=7329)[0m Successful requests:                     50        
[36m(vllm-benchmark, pid=7329)[0m Benchmark duration (s):                  102.93    
[36m(vllm-benchmark, pid=7329)[0m Total input tokens:                      50000     
[36m(vllm-benchmark, pid=7329)[0m Total generated tokens:                  100000    
[36m(vllm-benchmark, pid=7329)[0m Request throughput (req/s):              0.49      
[36m(vllm-benchmark, pid=7329)[0m Output token throughput (tok/s):         971.49    
[36m(vllm-benchmark, pid=7329)[0m Total Token throughput (tok/s):          1457.24   
[36m(vllm-benchmark, pid=7329)[0m ---------------Time to First Token----------------
[36m(vllm-benchmark, pid=7329)[0m Mean TTFT (ms):                          6154.71   
[36m(vllm-benchmark, pid=7329)[0m Median TTFT (ms):                        7504.63   
[36m(vllm-benchmark, pid=7329)[0m P99 TTFT (ms):                           8181.73   
[36m(vllm-benchmark, pid=7329)[0m -----Time per Output Token (excl. 1st token)------
[36m(vllm-benchmark, pid=7329)[0m Mean TPOT (ms):                          47.30     
[36m(vllm-benchmark, pid=7329)[0m Median TPOT (ms):                        46.45     
[36m(vllm-benchmark, pid=7329)[0m P99 TPOT (ms):                           51.16     
[36m(vllm-benchmark, pid=7329)[0m ---------------Inter-token Latency----------------
[36m(vllm-benchmark, pid=7329)[0m Mean ITL (ms):                           47.30     
[36m(vllm-benchmark, pid=7329)[0m Median ITL (ms):                         46.11     
[36m(vllm-benchmark, pid=7329)[0m P99 ITL (ms):                            48.53     
[36m(vllm-benchmark, pid=7329)[0m ==================================================
[36m(vllm-benchmark, pid=7329)[0m + sleep 6
[36m(vllm-benchmark, pid=7329)[0m + for pair in "1000,2000" "5000,1000" "10000,500" "30000,100" "sharegpt"
[36m(vllm-benchmark, pid=7329)[0m + '[' sgl == trt ']'
[36m(vllm-benchmark, pid=7329)[0m + just run-scenario sgl deepseek-r1 5000,1000
[36m(vllm-benchmark, pid=7329)[0m + just _ensure-results-dir deepseek-r1
[36m(vllm-benchmark, pid=7329)[0m mkdir -p results/deepseek-r1
[36m(vllm-benchmark, pid=7329)[0m + '[' sgl '!=' vllm ']'
[36m(vllm-benchmark, pid=7329)[0m + '[' sgl '!=' sgl ']'
[36m(vllm-benchmark, pid=7329)[0m ++ just _get-model-path deepseek-r1
[36m(vllm-benchmark, pid=7329)[0m + MODEL_PATH=deepseek-ai/DeepSeek-R1
[36m(vllm-benchmark, pid=7329)[0m ++ echo 5000,1000
[36m(vllm-benchmark, pid=7329)[0m ++ cut -d, -f1
[36m(vllm-benchmark, pid=7329)[0m + INPUT_LEN=5000
[36m(vllm-benchmark, pid=7329)[0m ++ echo 5000,1000
[36m(vllm-benchmark, pid=7329)[0m ++ cut -d, -f2
[36m(vllm-benchmark, pid=7329)[0m + OUTPUT_LEN=1000
[36m(vllm-benchmark, pid=7329)[0m + [[ '' == \s\g\l ]]
[36m(vllm-benchmark, pid=7329)[0m + [[ 5000,1000 == \s\h\a\r\e\g\p\t ]]
[36m(vllm-benchmark, pid=7329)[0m + uv run --with-requirements requirements-benchmark.txt vllm-benchmarks/benchmarks/benchmark_serving.py --model deepseek-ai/DeepSeek-R1 --dataset-name random --ignore-eos --num-prompts 50 --request-rate 10 --random-input-len 5000 --random-output-len 1000 --save-result --result-dir results/deepseek-r1 --result-filename sgl-5000-1000-.json
[36m(vllm-benchmark, pid=7329)[0m INFO 04-20 01:49:32 [__init__.py:239] Automatically detected platform cuda.
[36m(vllm-benchmark, pid=7329)[0m Namespace(backend='vllm', base_url=None, host='127.0.0.1', port=8000, endpoint='/v1/completions', dataset_name='random', dataset_path=None, max_concurrency=None, model='deepseek-ai/DeepSeek-R1', tokenizer=None, use_beam_search=False, num_prompts=50, logprobs=None, request_rate=10.0, burstiness=1.0, seed=0, trust_remote_code=False, disable_tqdm=False, profile=False, save_result=True, save_detailed=False, metadata=None, result_dir='results/deepseek-r1', result_filename='sgl-5000-1000-.json', ignore_eos=True, percentile_metrics='ttft,tpot,itl', metric_percentiles='99', goodput=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, sharegpt_output_len=None, random_input_len=5000, random_output_len=1000, random_range_ratio=0.0, random_prefix_len=0, hf_subset=None, hf_split=None, hf_output_len=None, top_p=None, top_k=None, min_p=None, temperature=None, tokenizer_mode='auto', served_model_name=None, lora_modules=None)
[36m(vllm-benchmark, pid=7329)[0m Starting initial single prompt test run...
[36m(vllm-benchmark, pid=7329)[0m Initial test run completed. Starting main benchmark run...
[36m(vllm-benchmark, pid=7329)[0m Traffic request rate: 10.0
[36m(vllm-benchmark, pid=7329)[0m Burstiness factor: 1.0 (Poisson process)
[36m(vllm-benchmark, pid=7329)[0m Maximum request concurrency: None
[36m(vllm-benchmark, pid=7329)[0m 
[36m(vllm-benchmark, pid=7329)[0m   0%|          | 0/50 [00:00<?, ?it/s]
[36m(vllm-benchmark, pid=7329)[0m   2%|▏         | 1/50 [01:01<49:59, 61.22s/it]
[36m(vllm-benchmark, pid=7329)[0m  50%|█████     | 25/50 [01:01<00:43,  1.74s/it]
 90%|█████████ | 45/50 [01:01<00:04,  1.24it/s]
100%|██████████| 50/50 [01:01<00:00,  1.23s/it]
[36m(vllm-benchmark, pid=7329)[0m ============ Serving Benchmark Result ============
[36m(vllm-benchmark, pid=7329)[0m Successful requests:                     50        
[36m(vllm-benchmark, pid=7329)[0m Benchmark duration (s):                  61.44     
[36m(vllm-benchmark, pid=7329)[0m Total input tokens:                      250000    
[36m(vllm-benchmark, pid=7329)[0m Total generated tokens:                  50000     
[36m(vllm-benchmark, pid=7329)[0m Request throughput (req/s):              0.81      
[36m(vllm-benchmark, pid=7329)[0m Output token throughput (tok/s):         813.83    
[36m(vllm-benchmark, pid=7329)[0m Total Token throughput (tok/s):          4882.95   
[36m(vllm-benchmark, pid=7329)[0m ---------------Time to First Token----------------
[36m(vllm-benchmark, pid=7329)[0m Mean TTFT (ms):                          9118.59   
[36m(vllm-benchmark, pid=7329)[0m Median TTFT (ms):                        9146.68   
[36m(vllm-benchmark, pid=7329)[0m P99 TTFT (ms):                           14603.01  
[36m(vllm-benchmark, pid=7329)[0m -----Time per Output Token (excl. 1st token)------
[36m(vllm-benchmark, pid=7329)[0m Mean TPOT (ms):                          50.09     
[36m(vllm-benchmark, pid=7329)[0m Median TPOT (ms):                        50.04     
[36m(vllm-benchmark, pid=7329)[0m P99 TPOT (ms):                           58.54     
[36m(vllm-benchmark, pid=7329)[0m ---------------Inter-token Latency----------------
[36m(vllm-benchmark, pid=7329)[0m Mean ITL (ms):                           50.09     
[36m(vllm-benchmark, pid=7329)[0m Median ITL (ms):                         42.60     
[36m(vllm-benchmark, pid=7329)[0m P99 ITL (ms):                            45.31     
[36m(vllm-benchmark, pid=7329)[0m ==================================================
[36m(vllm-benchmark, pid=7329)[0m + sleep 6
[36m(vllm-benchmark, pid=7329)[0m + for pair in "1000,2000" "5000,1000" "10000,500" "30000,100" "sharegpt"
[36m(vllm-benchmark, pid=7329)[0m + '[' sgl == trt ']'
[36m(vllm-benchmark, pid=7329)[0m + just run-scenario sgl deepseek-r1 10000,500
[36m(vllm-benchmark, pid=7329)[0m + just _ensure-results-dir deepseek-r1
[36m(vllm-benchmark, pid=7329)[0m mkdir -p results/deepseek-r1
[36m(vllm-benchmark, pid=7329)[0m + '[' sgl '!=' vllm ']'
[36m(vllm-benchmark, pid=7329)[0m + '[' sgl '!=' sgl ']'
[36m(vllm-benchmark, pid=7329)[0m ++ just _get-model-path deepseek-r1
[36m(vllm-benchmark, pid=7329)[0m + MODEL_PATH=deepseek-ai/DeepSeek-R1
[36m(vllm-benchmark, pid=7329)[0m ++ echo 10000,500
[36m(vllm-benchmark, pid=7329)[0m ++ cut -d, -f1
[36m(vllm-benchmark, pid=7329)[0m + INPUT_LEN=10000
[36m(vllm-benchmark, pid=7329)[0m ++ echo 10000,500
[36m(vllm-benchmark, pid=7329)[0m ++ cut -d, -f2
[36m(vllm-benchmark, pid=7329)[0m + OUTPUT_LEN=500
[36m(vllm-benchmark, pid=7329)[0m + [[ '' == \s\g\l ]]
[36m(vllm-benchmark, pid=7329)[0m + [[ 10000,500 == \s\h\a\r\e\g\p\t ]]
[36m(vllm-benchmark, pid=7329)[0m + uv run --with-requirements requirements-benchmark.txt vllm-benchmarks/benchmarks/benchmark_serving.py --model deepseek-ai/DeepSeek-R1 --dataset-name random --ignore-eos --num-prompts 50 --request-rate 10 --random-input-len 10000 --random-output-len 500 --save-result --result-dir results/deepseek-r1 --result-filename sgl-10000-500-.json
[36m(vllm-benchmark, pid=7329)[0m INFO 04-20 01:51:11 [__init__.py:239] Automatically detected platform cuda.
[36m(vllm-benchmark, pid=7329)[0m Namespace(backend='vllm', base_url=None, host='127.0.0.1', port=8000, endpoint='/v1/completions', dataset_name='random', dataset_path=None, max_concurrency=None, model='deepseek-ai/DeepSeek-R1', tokenizer=None, use_beam_search=False, num_prompts=50, logprobs=None, request_rate=10.0, burstiness=1.0, seed=0, trust_remote_code=False, disable_tqdm=False, profile=False, save_result=True, save_detailed=False, metadata=None, result_dir='results/deepseek-r1', result_filename='sgl-10000-500-.json', ignore_eos=True, percentile_metrics='ttft,tpot,itl', metric_percentiles='99', goodput=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, sharegpt_output_len=None, random_input_len=10000, random_output_len=500, random_range_ratio=0.0, random_prefix_len=0, hf_subset=None, hf_split=None, hf_output_len=None, top_p=None, top_k=None, min_p=None, temperature=None, tokenizer_mode='auto', served_model_name=None, lora_modules=None)
[36m(vllm-benchmark, pid=7329)[0m Starting initial single prompt test run...
[36m(vllm-benchmark, pid=7329)[0m Initial test run completed. Starting main benchmark run...
[36m(vllm-benchmark, pid=7329)[0m Traffic request rate: 10.0
[36m(vllm-benchmark, pid=7329)[0m Burstiness factor: 1.0 (Poisson process)
[36m(vllm-benchmark, pid=7329)[0m Maximum request concurrency: None
[36m(vllm-benchmark, pid=7329)[0m 
[36m(vllm-benchmark, pid=7329)[0m   0%|          | 0/50 [00:00<?, ?it/s]
[36m(vllm-benchmark, pid=7329)[0m   2%|▏         | 1/50 [01:03<51:59, 63.65s/it]
[36m(vllm-benchmark, pid=7329)[0m  38%|███▊      | 19/50 [01:03<01:14,  2.39s/it]
 74%|███████▍  | 37/50 [01:04<00:13,  1.01s/it]
100%|██████████| 50/50 [01:04<00:00,  1.28s/it]
[36m(vllm-benchmark, pid=7329)[0m ============ Serving Benchmark Result ============
[36m(vllm-benchmark, pid=7329)[0m Successful requests:                     50        
[36m(vllm-benchmark, pid=7329)[0m Benchmark duration (s):                  64.05     
[36m(vllm-benchmark, pid=7329)[0m Total input tokens:                      500000    
[36m(vllm-benchmark, pid=7329)[0m Total generated tokens:                  25000     
[36m(vllm-benchmark, pid=7329)[0m Request throughput (req/s):              0.78      
[36m(vllm-benchmark, pid=7329)[0m Output token throughput (tok/s):         390.35    
[36m(vllm-benchmark, pid=7329)[0m Total Token throughput (tok/s):          8197.35   
[36m(vllm-benchmark, pid=7329)[0m ---------------Time to First Token----------------
[36m(vllm-benchmark, pid=7329)[0m Mean TTFT (ms):                          21561.27  
[36m(vllm-benchmark, pid=7329)[0m Median TTFT (ms):                        22814.57  
[36m(vllm-benchmark, pid=7329)[0m P99 TTFT (ms):                           36931.45  
[36m(vllm-benchmark, pid=7329)[0m -----Time per Output Token (excl. 1st token)------
[36m(vllm-benchmark, pid=7329)[0m Mean TPOT (ms):                          80.35     
[36m(vllm-benchmark, pid=7329)[0m Median TPOT (ms):                        78.26     
[36m(vllm-benchmark, pid=7329)[0m P99 TPOT (ms):                           115.81    
[36m(vllm-benchmark, pid=7329)[0m ---------------Inter-token Latency----------------
[36m(vllm-benchmark, pid=7329)[0m Mean ITL (ms):                           80.35     
[36m(vllm-benchmark, pid=7329)[0m Median ITL (ms):                         45.44     
[36m(vllm-benchmark, pid=7329)[0m P99 ITL (ms):                            256.58    
[36m(vllm-benchmark, pid=7329)[0m ==================================================
[36m(vllm-benchmark, pid=7329)[0m + sleep 6
[36m(vllm-benchmark, pid=7329)[0m + for pair in "1000,2000" "5000,1000" "10000,500" "30000,100" "sharegpt"
[36m(vllm-benchmark, pid=7329)[0m + '[' sgl == trt ']'
[36m(vllm-benchmark, pid=7329)[0m + just run-scenario sgl deepseek-r1 30000,100
[36m(vllm-benchmark, pid=7329)[0m + just _ensure-results-dir deepseek-r1
[36m(vllm-benchmark, pid=7329)[0m mkdir -p results/deepseek-r1
[36m(vllm-benchmark, pid=7329)[0m + '[' sgl '!=' vllm ']'
[36m(vllm-benchmark, pid=7329)[0m + '[' sgl '!=' sgl ']'
[36m(vllm-benchmark, pid=7329)[0m ++ just _get-model-path deepseek-r1
[36m(vllm-benchmark, pid=7329)[0m + MODEL_PATH=deepseek-ai/DeepSeek-R1
[36m(vllm-benchmark, pid=7329)[0m ++ cut -d, -f1
[36m(vllm-benchmark, pid=7329)[0m ++ echo 30000,100
[36m(vllm-benchmark, pid=7329)[0m + INPUT_LEN=30000
[36m(vllm-benchmark, pid=7329)[0m ++ echo 30000,100
[36m(vllm-benchmark, pid=7329)[0m ++ cut -d, -f2
[36m(vllm-benchmark, pid=7329)[0m + OUTPUT_LEN=100
[36m(vllm-benchmark, pid=7329)[0m + [[ '' == \s\g\l ]]
[36m(vllm-benchmark, pid=7329)[0m + [[ 30000,100 == \s\h\a\r\e\g\p\t ]]
[36m(vllm-benchmark, pid=7329)[0m + uv run --with-requirements requirements-benchmark.txt vllm-benchmarks/benchmarks/benchmark_serving.py --model deepseek-ai/DeepSeek-R1 --dataset-name random --ignore-eos --num-prompts 50 --request-rate 10 --random-input-len 30000 --random-output-len 100 --save-result --result-dir results/deepseek-r1 --result-filename sgl-30000-100-.json
[36m(vllm-benchmark, pid=7329)[0m INFO 04-20 01:52:43 [__init__.py:239] Automatically detected platform cuda.
[36m(vllm-benchmark, pid=7329)[0m Namespace(backend='vllm', base_url=None, host='127.0.0.1', port=8000, endpoint='/v1/completions', dataset_name='random', dataset_path=None, max_concurrency=None, model='deepseek-ai/DeepSeek-R1', tokenizer=None, use_beam_search=False, num_prompts=50, logprobs=None, request_rate=10.0, burstiness=1.0, seed=0, trust_remote_code=False, disable_tqdm=False, profile=False, save_result=True, save_detailed=False, metadata=None, result_dir='results/deepseek-r1', result_filename='sgl-30000-100-.json', ignore_eos=True, percentile_metrics='ttft,tpot,itl', metric_percentiles='99', goodput=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, sharegpt_output_len=None, random_input_len=30000, random_output_len=100, random_range_ratio=0.0, random_prefix_len=0, hf_subset=None, hf_split=None, hf_output_len=None, top_p=None, top_k=None, min_p=None, temperature=None, tokenizer_mode='auto', served_model_name=None, lora_modules=None)
[36m(vllm-benchmark, pid=7329)[0m Starting initial single prompt test run...
[36m(vllm-benchmark, pid=7329)[0m Initial test run completed. Starting main benchmark run...
[36m(vllm-benchmark, pid=7329)[0m Traffic request rate: 10.0
[36m(vllm-benchmark, pid=7329)[0m Burstiness factor: 1.0 (Poisson process)
[36m(vllm-benchmark, pid=7329)[0m Maximum request concurrency: None
[36m(vllm-benchmark, pid=7329)[0m 
[36m(vllm-benchmark, pid=7329)[0m   0%|          | 0/50 [00:00<?, ?it/s]
[36m(vllm-benchmark, pid=7329)[0m   2%|▏         | 1/50 [02:29<2:02:18, 149.77s/it]
[36m(vllm-benchmark, pid=7329)[0m  74%|███████▍  | 37/50 [02:30<00:37,  2.89s/it]  
100%|██████████| 50/50 [02:31<00:00,  3.02s/it]
[36m(vllm-benchmark, pid=7329)[0m ============ Serving Benchmark Result ============
[36m(vllm-benchmark, pid=7329)[0m Successful requests:                     50        
[36m(vllm-benchmark, pid=7329)[0m Benchmark duration (s):                  151.01    
[36m(vllm-benchmark, pid=7329)[0m Total input tokens:                      1500000   
[36m(vllm-benchmark, pid=7329)[0m Total generated tokens:                  5000      
[36m(vllm-benchmark, pid=7329)[0m Request throughput (req/s):              0.33      
[36m(vllm-benchmark, pid=7329)[0m Output token throughput (tok/s):         33.11     
[36m(vllm-benchmark, pid=7329)[0m Total Token throughput (tok/s):          9966.31   
[36m(vllm-benchmark, pid=7329)[0m ---------------Time to First Token----------------
[36m(vllm-benchmark, pid=7329)[0m Mean TTFT (ms):                          81772.66  
[36m(vllm-benchmark, pid=7329)[0m Median TTFT (ms):                        88806.54  
[36m(vllm-benchmark, pid=7329)[0m P99 TTFT (ms):                           141585.04 
[36m(vllm-benchmark, pid=7329)[0m -----Time per Output Token (excl. 1st token)------
[36m(vllm-benchmark, pid=7329)[0m Mean TPOT (ms):                          668.59    
[36m(vllm-benchmark, pid=7329)[0m Median TPOT (ms):                        606.58    
[36m(vllm-benchmark, pid=7329)[0m P99 TPOT (ms):                           1236.21   
[36m(vllm-benchmark, pid=7329)[0m ---------------Inter-token Latency----------------
[36m(vllm-benchmark, pid=7329)[0m Mean ITL (ms):                           668.59    
[36m(vllm-benchmark, pid=7329)[0m Median ITL (ms):                         52.04     
[36m(vllm-benchmark, pid=7329)[0m P99 ITL (ms):                            612.81    
[36m(vllm-benchmark, pid=7329)[0m ==================================================
[36m(vllm-benchmark, pid=7329)[0m + sleep 6
[36m(vllm-benchmark, pid=7329)[0m + for pair in "1000,2000" "5000,1000" "10000,500" "30000,100" "sharegpt"
[36m(vllm-benchmark, pid=7329)[0m + '[' sgl == trt ']'
[36m(vllm-benchmark, pid=7329)[0m + just run-scenario sgl deepseek-r1 sharegpt
[36m(vllm-benchmark, pid=7329)[0m + just _ensure-results-dir deepseek-r1
[36m(vllm-benchmark, pid=7329)[0m mkdir -p results/deepseek-r1
[36m(vllm-benchmark, pid=7329)[0m + '[' sgl '!=' vllm ']'
[36m(vllm-benchmark, pid=7329)[0m + '[' sgl '!=' sgl ']'
[36m(vllm-benchmark, pid=7329)[0m ++ just _get-model-path deepseek-r1
[36m(vllm-benchmark, pid=7329)[0m + MODEL_PATH=deepseek-ai/DeepSeek-R1
[36m(vllm-benchmark, pid=7329)[0m ++ echo sharegpt
[36m(vllm-benchmark, pid=7329)[0m ++ cut -d, -f1
[36m(vllm-benchmark, pid=7329)[0m + INPUT_LEN=sharegpt
[36m(vllm-benchmark, pid=7329)[0m ++ echo sharegpt
[36m(vllm-benchmark, pid=7329)[0m ++ cut -d, -f2
[36m(vllm-benchmark, pid=7329)[0m + OUTPUT_LEN=sharegpt
[36m(vllm-benchmark, pid=7329)[0m + [[ '' == \s\g\l ]]
[36m(vllm-benchmark, pid=7329)[0m + [[ sharegpt == \s\h\a\r\e\g\p\t ]]
[36m(vllm-benchmark, pid=7329)[0m + uv run --with-requirements requirements-benchmark.txt vllm-benchmarks/benchmarks/benchmark_serving.py --model deepseek-ai/DeepSeek-R1 --dataset-name sharegpt --ignore-eos --dataset-path vllm-benchmarks/benchmarks/sharegpt.json --num-prompts 500 --request-rate 10 --save-result --result-dir results/deepseek-r1 --result-filename sgl-sharegpt-.json
[36m(vllm-benchmark, pid=7329)[0m INFO 04-20 01:55:42 [__init__.py:239] Automatically detected platform cuda.
[36m(vllm-benchmark, pid=7329)[0m Namespace(backend='vllm', base_url=None, host='127.0.0.1', port=8000, endpoint='/v1/completions', dataset_name='sharegpt', dataset_path='vllm-benchmarks/benchmarks/sharegpt.json', max_concurrency=None, model='deepseek-ai/DeepSeek-R1', tokenizer=None, use_beam_search=False, num_prompts=500, logprobs=None, request_rate=10.0, burstiness=1.0, seed=0, trust_remote_code=False, disable_tqdm=False, profile=False, save_result=True, save_detailed=False, metadata=None, result_dir='results/deepseek-r1', result_filename='sgl-sharegpt-.json', ignore_eos=True, percentile_metrics='ttft,tpot,itl', metric_percentiles='99', goodput=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, sharegpt_output_len=None, random_input_len=1024, random_output_len=128, random_range_ratio=0.0, random_prefix_len=0, hf_subset=None, hf_split=None, hf_output_len=None, top_p=None, top_k=None, min_p=None, temperature=None, tokenizer_mode='auto', served_model_name=None, lora_modules=None)
[36m(vllm-benchmark, pid=7329)[0m Starting initial single prompt test run...
[36m(vllm-benchmark, pid=7329)[0m Initial test run completed. Starting main benchmark run...
[36m(vllm-benchmark, pid=7329)[0m Traffic request rate: 10.0
[36m(vllm-benchmark, pid=7329)[0m Burstiness factor: 1.0 (Poisson process)
[36m(vllm-benchmark, pid=7329)[0m Maximum request concurrency: None
[36m(vllm-benchmark, pid=7329)[0m 
[36m(vllm-benchmark, pid=7329)[0m   0%|          | 0/500 [00:00<?, ?it/s]
[36m(vllm-benchmark, pid=7329)[0m   0%|          | 1/500 [00:01<15:45,  1.89s/it]
[36m(vllm-benchmark, pid=7329)[0m   0%|          | 2/500 [00:02<07:18,  1.14it/s]
[36m(vllm-benchmark, pid=7329)[0m   1%|          | 3/500 [00:02<07:09,  1.16it/s]
[36m(vllm-benchmark, pid=7329)[0m   1%|          | 4/500 [00:04<10:11,  1.23s/it]
[36m(vllm-benchmark, pid=7329)[0m   1%|          | 5/500 [00:04<07:00,  1.18it/s]
[36m(vllm-benchmark, pid=7329)[0m   1%|▏         | 7/500 [00:06<05:53,  1.40it/s]
[36m(vllm-benchmark, pid=7329)[0m   2%|▏         | 8/500 [00:21<37:05,  4.52s/it]
[36m(vllm-benchmark, pid=7329)[0m   2%|▏         | 9/500 [00:22<29:49,  3.65s/it]
[36m(vllm-benchmark, pid=7329)[0m   2%|▏         | 10/500 [00:29<37:34,  4.60s/it]
[36m(vllm-benchmark, pid=7329)[0m   2%|▏         | 11/500 [00:30<29:26,  3.61s/it]
[36m(vllm-benchmark, pid=7329)[0m   2%|▏         | 12/500 [00:30<21:23,  2.63s/it]
[36m(vllm-benchmark, pid=7329)[0m   3%|▎         | 13/500 [00:30<15:25,  1.90s/it]
[36m(vllm-benchmark, pid=7329)[0m   4%|▎         | 18/500 [00:31<05:19,  1.51it/s]
[36m(vllm-benchmark, pid=7329)[0m   4%|▍         | 21/500 [00:31<03:32,  2.25it/s]
[36m(vllm-benchmark, pid=7329)[0m   5%|▌         | 26/500 [00:31<02:06,  3.76it/s]
[36m(vllm-benchmark, pid=7329)[0m   6%|▌         | 30/500 [00:32<01:29,  5.25it/s]
[36m(vllm-benchmark, pid=7329)[0m   6%|▋         | 32/500 [00:32<01:19,  5.91it/s]
[36m(vllm-benchmark, pid=7329)[0m   7%|▋         | 34/500 [00:32<01:14,  6.30it/s]
[36m(vllm-benchmark, pid=7329)[0m   7%|▋         | 36/500 [00:32<01:25,  5.46it/s]
[36m(vllm-benchmark, pid=7329)[0m   8%|▊         | 40/500 [00:33<00:59,  7.73it/s]
[36m(vllm-benchmark, pid=7329)[0m   8%|▊         | 42/500 [00:33<01:02,  7.35it/s]
[36m(vllm-benchmark, pid=7329)[0m  10%|▉         | 48/500 [00:33<00:45,  9.87it/s]
[36m(vllm-benchmark, pid=7329)[0m  10%|█         | 51/500 [00:34<00:40, 11.01it/s]
[36m(vllm-benchmark, pid=7329)[0m  11%|█         | 53/500 [00:34<00:41, 10.69it/s]
[36m(vllm-benchmark, pid=7329)[0m  11%|█         | 56/500 [00:34<00:37, 11.82it/s]
[36m(vllm-benchmark, pid=7329)[0m  12%|█▏        | 58/500 [00:34<00:39, 11.32it/s]
[36m(vllm-benchmark, pid=7329)[0m  12%|█▏        | 61/500 [00:34<00:34, 12.76it/s]
[36m(vllm-benchmark, pid=7329)[0m  13%|█▎        | 65/500 [00:35<00:35, 12.21it/s]
[36m(vllm-benchmark, pid=7329)[0m  13%|█▎        | 67/500 [00:35<00:45,  9.59it/s]
[36m(vllm-benchmark, pid=7329)[0m  14%|█▍        | 70/500 [00:35<00:38, 11.28it/s]
[36m(vllm-benchmark, pid=7329)[0m  16%|█▌        | 79/500 [00:36<00:25, 16.75it/s]
[36m(vllm-benchmark, pid=7329)[0m  17%|█▋        | 87/500 [00:36<00:21, 19.23it/s]
[36m(vllm-benchmark, pid=7329)[0m  18%|█▊        | 90/500 [00:36<00:26, 15.40it/s]
[36m(vllm-benchmark, pid=7329)[0m  19%|█▉        | 96/500 [00:37<00:22, 18.09it/s]
[36m(vllm-benchmark, pid=7329)[0m  20%|█▉        | 98/500 [00:37<00:27, 14.68it/s]
[36m(vllm-benchmark, pid=7329)[0m  20%|██        | 100/500 [00:37<00:34, 11.58it/s]
[36m(vllm-benchmark, pid=7329)[0m  20%|██        | 102/500 [00:37<00:36, 10.90it/s]
[36m(vllm-benchmark, pid=7329)[0m  21%|██        | 104/500 [00:38<00:42,  9.42it/s]
[36m(vllm-benchmark, pid=7329)[0m  21%|██        | 105/500 [00:38<01:13,  5.36it/s]
[36m(vllm-benchmark, pid=7329)[0m  21%|██        | 106/500 [00:39<01:11,  5.52it/s]
[36m(vllm-benchmark, pid=7329)[0m  22%|██▏       | 109/500 [00:39<00:54,  7.24it/s]
[36m(vllm-benchmark, pid=7329)[0m  22%|██▏       | 110/500 [00:39<01:05,  5.94it/s]
[36m(vllm-benchmark, pid=7329)[0m  23%|██▎       | 113/500 [00:39<00:56,  6.88it/s]
[36m(vllm-benchmark, pid=7329)[0m  24%|██▍       | 121/500 [00:40<00:37,  9.99it/s]
[36m(vllm-benchmark, pid=7329)[0m  25%|██▍       | 123/500 [00:40<00:41,  9.18it/s]
[36m(vllm-benchmark, pid=7329)[0m  25%|██▍       | 124/500 [00:41<01:02,  6.02it/s]
[36m(vllm-benchmark, pid=7329)[0m  25%|██▌       | 126/500 [00:42<01:17,  4.85it/s]
[36m(vllm-benchmark, pid=7329)[0m  26%|██▌       | 128/500 [00:42<01:06,  5.58it/s]
[36m(vllm-benchmark, pid=7329)[0m  26%|██▌       | 129/500 [00:42<01:06,  5.60it/s]
[36m(vllm-benchmark, pid=7329)[0m  26%|██▌       | 130/500 [00:42<01:05,  5.61it/s]
[36m(vllm-benchmark, pid=7329)[0m  26%|██▌       | 131/500 [00:42<01:03,  5.80it/s]
[36m(vllm-benchmark, pid=7329)[0m  27%|██▋       | 136/500 [00:43<00:34, 10.67it/s]
[36m(vllm-benchmark, pid=7329)[0m  28%|██▊       | 138/500 [00:43<00:59,  6.08it/s]
[36m(vllm-benchmark, pid=7329)[0m  28%|██▊       | 140/500 [00:44<00:59,  6.07it/s]
[36m(vllm-benchmark, pid=7329)[0m  28%|██▊       | 142/500 [00:44<00:52,  6.82it/s]
[36m(vllm-benchmark, pid=7329)[0m  29%|██▊       | 143/500 [00:44<00:53,  6.66it/s]
[36m(vllm-benchmark, pid=7329)[0m  29%|██▉       | 146/500 [00:44<00:40,  8.68it/s]
[36m(vllm-benchmark, pid=7329)[0m  30%|██▉       | 148/500 [00:44<00:39,  9.01it/s]
[36m(vllm-benchmark, pid=7329)[0m  30%|███       | 150/500 [00:59<13:06,  2.25s/it]
[36m(vllm-benchmark, pid=7329)[0m  30%|███       | 151/500 [01:00<11:05,  1.91s/it]
[36m(vllm-benchmark, pid=7329)[0m  30%|███       | 152/500 [01:00<09:15,  1.60s/it]
[36m(vllm-benchmark, pid=7329)[0m  31%|███       | 153/500 [01:00<07:41,  1.33s/it]
[36m(vllm-benchmark, pid=7329)[0m  31%|███       | 156/500 [01:01<04:15,  1.35it/s]
[36m(vllm-benchmark, pid=7329)[0m  32%|███▏      | 158/500 [01:01<03:12,  1.77it/s]
[36m(vllm-benchmark, pid=7329)[0m  33%|███▎      | 166/500 [01:01<01:12,  4.60it/s]
[36m(vllm-benchmark, pid=7329)[0m  34%|███▎      | 168/500 [01:02<01:08,  4.88it/s]
[36m(vllm-benchmark, pid=7329)[0m  35%|███▍      | 173/500 [01:02<00:49,  6.58it/s]
[36m(vllm-benchmark, pid=7329)[0m  35%|███▌      | 176/500 [01:02<00:41,  7.74it/s]
[36m(vllm-benchmark, pid=7329)[0m  36%|███▌      | 178/500 [01:02<00:44,  7.17it/s]
[36m(vllm-benchmark, pid=7329)[0m  36%|███▌      | 180/500 [01:03<00:47,  6.75it/s]
[36m(vllm-benchmark, pid=7329)[0m  36%|███▌      | 181/500 [01:03<00:55,  5.75it/s]
[36m(vllm-benchmark, pid=7329)[0m  37%|███▋      | 183/500 [01:03<00:53,  5.97it/s]
[36m(vllm-benchmark, pid=7329)[0m  37%|███▋      | 185/500 [01:04<00:53,  5.87it/s]
[36m(vllm-benchmark, pid=7329)[0m  38%|███▊      | 188/500 [01:04<00:41,  7.47it/s]
[36m(vllm-benchmark, pid=7329)[0m  38%|███▊      | 190/500 [01:05<00:51,  6.05it/s]
[36m(vllm-benchmark, pid=7329)[0m  38%|███▊      | 191/500 [01:05<00:59,  5.17it/s]
[36m(vllm-benchmark, pid=7329)[0m  38%|███▊      | 192/500 [01:05<01:17,  3.98it/s]
[36m(vllm-benchmark, pid=7329)[0m  39%|███▊      | 193/500 [01:06<01:11,  4.31it/s]
[36m(vllm-benchmark, pid=7329)[0m  39%|███▉      | 197/500 [01:06<00:44,  6.81it/s]
[36m(vllm-benchmark, pid=7329)[0m  40%|███▉      | 199/500 [01:06<00:46,  6.50it/s]
[36m(vllm-benchmark, pid=7329)[0m  40%|████      | 200/500 [01:07<00:55,  5.37it/s]
[36m(vllm-benchmark, pid=7329)[0m  40%|████      | 201/500 [01:07<00:57,  5.20it/s]
[36m(vllm-benchmark, pid=7329)[0m  40%|████      | 202/500 [01:07<01:17,  3.83it/s]
[36m(vllm-benchmark, pid=7329)[0m  41%|████      | 203/500 [01:08<01:22,  3.60it/s]
[36m(vllm-benchmark, pid=7329)[0m  41%|████      | 204/500 [01:08<01:13,  4.00it/s]
[36m(vllm-benchmark, pid=7329)[0m  41%|████      | 205/500 [01:08<01:34,  3.12it/s]
[36m(vllm-benchmark, pid=7329)[0m  41%|████      | 206/500 [01:08<01:21,  3.61it/s]
[36m(vllm-benchmark, pid=7329)[0m  42%|████▏     | 209/500 [01:09<01:19,  3.67it/s]
[36m(vllm-benchmark, pid=7329)[0m  42%|████▏     | 211/500 [01:10<01:10,  4.13it/s]
[36m(vllm-benchmark, pid=7329)[0m  43%|████▎     | 213/500 [01:10<01:00,  4.71it/s]
[36m(vllm-benchmark, pid=7329)[0m  43%|████▎     | 216/500 [01:10<00:48,  5.85it/s]
[36m(vllm-benchmark, pid=7329)[0m  43%|████▎     | 217/500 [01:11<01:14,  3.81it/s]
[36m(vllm-benchmark, pid=7329)[0m  44%|████▎     | 218/500 [01:11<01:24,  3.32it/s]
[36m(vllm-benchmark, pid=7329)[0m  44%|████▍     | 219/500 [01:12<01:39,  2.81it/s]
[36m(vllm-benchmark, pid=7329)[0m  44%|████▍     | 220/500 [01:13<01:47,  2.61it/s]
[36m(vllm-benchmark, pid=7329)[0m  44%|████▍     | 221/500 [01:13<01:46,  2.63it/s]
[36m(vllm-benchmark, pid=7329)[0m  44%|████▍     | 222/500 [01:13<01:30,  3.08it/s]
[36m(vllm-benchmark, pid=7329)[0m  45%|████▍     | 223/500 [01:13<01:19,  3.50it/s]
[36m(vllm-benchmark, pid=7329)[0m  45%|████▌     | 225/500 [01:14<01:03,  4.30it/s]
[36m(vllm-benchmark, pid=7329)[0m  45%|████▌     | 227/500 [01:14<00:56,  4.79it/s]
[36m(vllm-benchmark, pid=7329)[0m  46%|████▌     | 228/500 [01:14<01:04,  4.23it/s]
[36m(vllm-benchmark, pid=7329)[0m  46%|████▌     | 229/500 [01:15<01:11,  3.81it/s]
[36m(vllm-benchmark, pid=7329)[0m  46%|████▌     | 230/500 [01:15<01:38,  2.73it/s]
[36m(vllm-benchmark, pid=7329)[0m  46%|████▋     | 232/500 [01:15<01:09,  3.88it/s]
[36m(vllm-benchmark, pid=7329)[0m  47%|████▋     | 233/500 [01:16<01:11,  3.76it/s]
[36m(vllm-benchmark, pid=7329)[0m  47%|████▋     | 234/500 [01:16<01:07,  3.96it/s]
[36m(vllm-benchmark, pid=7329)[0m  47%|████▋     | 235/500 [01:16<01:09,  3.80it/s]
[36m(vllm-benchmark, pid=7329)[0m  47%|████▋     | 237/500 [01:17<01:29,  2.94it/s]
[36m(vllm-benchmark, pid=7329)[0m  48%|████▊     | 238/500 [01:18<01:29,  2.94it/s]
[36m(vllm-benchmark, pid=7329)[0m  48%|████▊     | 242/500 [01:18<00:48,  5.29it/s]
[36m(vllm-benchmark, pid=7329)[0m  49%|████▉     | 245/500 [01:18<00:41,  6.08it/s]
[36m(vllm-benchmark, pid=7329)[0m  49%|████▉     | 247/500 [01:19<00:42,  6.02it/s]
[36m(vllm-benchmark, pid=7329)[0m  50%|████▉     | 248/500 [01:19<01:02,  4.03it/s]
[36m(vllm-benchmark, pid=7329)[0m  50%|█████     | 250/500 [01:20<00:54,  4.58it/s]
[36m(vllm-benchmark, pid=7329)[0m  50%|█████     | 251/500 [01:20<01:08,  3.62it/s]
[36m(vllm-benchmark, pid=7329)[0m  51%|█████     | 253/500 [01:21<01:06,  3.71it/s]
[36m(vllm-benchmark, pid=7329)[0m  51%|█████     | 255/500 [01:21<01:17,  3.16it/s]
[36m(vllm-benchmark, pid=7329)[0m  51%|█████     | 256/500 [01:22<01:27,  2.79it/s]
[36m(vllm-benchmark, pid=7329)[0m  51%|█████▏    | 257/500 [01:22<01:17,  3.15it/s]
[36m(vllm-benchmark, pid=7329)[0m  52%|█████▏    | 258/500 [01:22<01:16,  3.17it/s]
[36m(vllm-benchmark, pid=7329)[0m  52%|█████▏    | 260/500 [01:23<01:02,  3.87it/s]
[36m(vllm-benchmark, pid=7329)[0m  52%|█████▏    | 262/500 [01:23<00:53,  4.42it/s]
[36m(vllm-benchmark, pid=7329)[0m  53%|█████▎    | 263/500 [01:23<01:00,  3.93it/s]
[36m(vllm-benchmark, pid=7329)[0m  53%|█████▎    | 265/500 [01:24<00:52,  4.46it/s]
[36m(vllm-benchmark, pid=7329)[0m  53%|█████▎    | 267/500 [01:24<00:40,  5.71it/s]
[36m(vllm-benchmark, pid=7329)[0m  54%|█████▎    | 268/500 [01:24<00:39,  5.90it/s]
[36m(vllm-benchmark, pid=7329)[0m  54%|█████▍    | 269/500 [01:24<00:39,  5.92it/s]
[36m(vllm-benchmark, pid=7329)[0m  54%|█████▍    | 270/500 [01:25<00:47,  4.82it/s]
[36m(vllm-benchmark, pid=7329)[0m  54%|█████▍    | 271/500 [01:25<00:47,  4.82it/s]
[36m(vllm-benchmark, pid=7329)[0m  54%|█████▍    | 272/500 [01:25<00:45,  5.02it/s]
[36m(vllm-benchmark, pid=7329)[0m  55%|█████▍    | 273/500 [01:25<00:51,  4.44it/s]
[36m(vllm-benchmark, pid=7329)[0m  55%|█████▌    | 276/500 [01:26<01:06,  3.37it/s]
[36m(vllm-benchmark, pid=7329)[0m  55%|█████▌    | 277/500 [01:27<01:13,  3.03it/s]
[36m(vllm-benchmark, pid=7329)[0m  56%|█████▌    | 281/500 [01:27<00:43,  5.03it/s]
[36m(vllm-benchmark, pid=7329)[0m  57%|█████▋    | 283/500 [01:27<00:37,  5.84it/s]
[36m(vllm-benchmark, pid=7329)[0m  57%|█████▋    | 284/500 [01:28<00:48,  4.49it/s]
[36m(vllm-benchmark, pid=7329)[0m  57%|█████▋    | 285/500 [01:28<01:05,  3.27it/s]
[36m(vllm-benchmark, pid=7329)[0m  57%|█████▋    | 287/500 [01:29<00:49,  4.29it/s]
[36m(vllm-benchmark, pid=7329)[0m  58%|█████▊    | 288/500 [01:29<00:46,  4.56it/s]
[36m(vllm-benchmark, pid=7329)[0m  58%|█████▊    | 289/500 [01:29<00:50,  4.19it/s]
[36m(vllm-benchmark, pid=7329)[0m  58%|█████▊    | 291/500 [01:30<00:58,  3.60it/s]
[36m(vllm-benchmark, pid=7329)[0m  59%|█████▊    | 293/500 [01:31<01:02,  3.30it/s]
[36m(vllm-benchmark, pid=7329)[0m  59%|█████▉    | 294/500 [01:31<01:03,  3.27it/s]
[36m(vllm-benchmark, pid=7329)[0m  59%|█████▉    | 297/500 [01:31<00:39,  5.13it/s]
[36m(vllm-benchmark, pid=7329)[0m  60%|█████▉    | 299/500 [01:32<00:47,  4.27it/s]
[36m(vllm-benchmark, pid=7329)[0m  60%|██████    | 302/500 [01:32<00:36,  5.38it/s]
[36m(vllm-benchmark, pid=7329)[0m  61%|██████    | 304/500 [01:32<00:32,  6.12it/s]
[36m(vllm-benchmark, pid=7329)[0m  61%|██████    | 305/500 [01:33<00:43,  4.50it/s]
[36m(vllm-benchmark, pid=7329)[0m  61%|██████    | 306/500 [01:33<00:47,  4.11it/s]
[36m(vllm-benchmark, pid=7329)[0m  61%|██████▏   | 307/500 [01:33<00:44,  4.37it/s]
[36m(vllm-benchmark, pid=7329)[0m  62%|██████▏   | 308/500 [01:33<00:40,  4.76it/s]
[36m(vllm-benchmark, pid=7329)[0m  62%|██████▏   | 309/500 [01:34<00:37,  5.12it/s]
[36m(vllm-benchmark, pid=7329)[0m  62%|██████▏   | 310/500 [01:34<00:37,  5.02it/s]
[36m(vllm-benchmark, pid=7329)[0m  62%|██████▏   | 311/500 [01:34<00:42,  4.44it/s]
[36m(vllm-benchmark, pid=7329)[0m  63%|██████▎   | 314/500 [01:35<00:36,  5.10it/s]
[36m(vllm-benchmark, pid=7329)[0m  63%|██████▎   | 315/500 [01:35<00:35,  5.18it/s]
[36m(vllm-benchmark, pid=7329)[0m  64%|██████▎   | 318/500 [01:35<00:28,  6.47it/s]
[36m(vllm-benchmark, pid=7329)[0m  64%|██████▍   | 320/500 [01:36<00:38,  4.71it/s]
[36m(vllm-benchmark, pid=7329)[0m  64%|██████▍   | 321/500 [01:36<00:37,  4.75it/s]
[36m(vllm-benchmark, pid=7329)[0m  64%|██████▍   | 322/500 [01:36<00:35,  5.01it/s]
[36m(vllm-benchmark, pid=7329)[0m  65%|██████▍   | 324/500 [01:36<00:32,  5.37it/s]
[36m(vllm-benchmark, pid=7329)[0m  65%|██████▌   | 325/500 [01:37<00:39,  4.46it/s]
[36m(vllm-benchmark, pid=7329)[0m  65%|██████▌   | 326/500 [01:38<00:57,  3.04it/s]
[36m(vllm-benchmark, pid=7329)[0m  65%|██████▌   | 327/500 [01:38<00:49,  3.47it/s]
[36m(vllm-benchmark, pid=7329)[0m  66%|██████▌   | 328/500 [01:38<00:44,  3.87it/s]
[36m(vllm-benchmark, pid=7329)[0m  66%|██████▌   | 329/500 [01:38<00:47,  3.58it/s]
[36m(vllm-benchmark, pid=7329)[0m  66%|██████▌   | 331/500 [01:39<00:44,  3.80it/s]
[36m(vllm-benchmark, pid=7329)[0m  66%|██████▋   | 332/500 [01:40<01:08,  2.46it/s]
[36m(vllm-benchmark, pid=7329)[0m  67%|██████▋   | 333/500 [01:40<01:03,  2.64it/s]
[36m(vllm-benchmark, pid=7329)[0m  67%|██████▋   | 335/500 [01:40<00:47,  3.45it/s]
[36m(vllm-benchmark, pid=7329)[0m  67%|██████▋   | 337/500 [01:41<00:46,  3.54it/s]
[36m(vllm-benchmark, pid=7329)[0m  68%|██████▊   | 338/500 [01:42<01:09,  2.33it/s]
[36m(vllm-benchmark, pid=7329)[0m  68%|██████▊   | 339/500 [01:42<01:00,  2.68it/s]
[36m(vllm-benchmark, pid=7329)[0m  68%|██████▊   | 340/500 [01:42<00:51,  3.12it/s]
[36m(vllm-benchmark, pid=7329)[0m  68%|██████▊   | 341/500 [01:42<00:44,  3.55it/s]
[36m(vllm-benchmark, pid=7329)[0m  69%|██████▉   | 345/500 [01:42<00:20,  7.42it/s]
[36m(vllm-benchmark, pid=7329)[0m  69%|██████▉   | 347/500 [01:43<00:22,  6.69it/s]
[36m(vllm-benchmark, pid=7329)[0m  70%|██████▉   | 349/500 [01:43<00:19,  7.93it/s]
[36m(vllm-benchmark, pid=7329)[0m  70%|███████   | 352/500 [01:43<00:14, 10.41it/s]
[36m(vllm-benchmark, pid=7329)[0m  71%|███████   | 354/500 [01:43<00:14, 10.07it/s]
[36m(vllm-benchmark, pid=7329)[0m  71%|███████   | 356/500 [01:44<00:16,  8.91it/s]
[36m(vllm-benchmark, pid=7329)[0m  72%|███████▏  | 358/500 [01:44<00:14,  9.91it/s]
[36m(vllm-benchmark, pid=7329)[0m  72%|███████▏  | 362/500 [01:44<00:09, 13.97it/s]
[36m(vllm-benchmark, pid=7329)[0m  73%|███████▎  | 364/500 [01:44<00:14,  9.41it/s]
[36m(vllm-benchmark, pid=7329)[0m  73%|███████▎  | 366/500 [01:45<00:16,  7.98it/s]
[36m(vllm-benchmark, pid=7329)[0m  74%|███████▍  | 369/500 [01:45<00:15,  8.72it/s]
[36m(vllm-benchmark, pid=7329)[0m  74%|███████▍  | 372/500 [01:45<00:11, 10.83it/s]
[36m(vllm-benchmark, pid=7329)[0m  75%|███████▍  | 374/500 [01:45<00:10, 11.55it/s]
[36m(vllm-benchmark, pid=7329)[0m  75%|███████▌  | 377/500 [01:45<00:09, 12.61it/s]
[36m(vllm-benchmark, pid=7329)[0m  76%|███████▌  | 380/500 [01:46<00:08, 14.81it/s]
[36m(vllm-benchmark, pid=7329)[0m  77%|███████▋  | 383/500 [01:46<00:07, 14.96it/s]
[36m(vllm-benchmark, pid=7329)[0m  77%|███████▋  | 385/500 [01:46<00:12,  8.95it/s]
[36m(vllm-benchmark, pid=7329)[0m  77%|███████▋  | 387/500 [01:46<00:12,  9.25it/s]
[36m(vllm-benchmark, pid=7329)[0m  78%|███████▊  | 389/500 [01:47<00:10, 10.34it/s]
[36m(vllm-benchmark, pid=7329)[0m  79%|███████▉  | 394/500 [01:47<00:11,  8.95it/s]
[36m(vllm-benchmark, pid=7329)[0m  79%|███████▉  | 396/500 [01:47<00:11,  8.68it/s]
[36m(vllm-benchmark, pid=7329)[0m  80%|███████▉  | 398/500 [01:48<00:11,  9.05it/s]
[36m(vllm-benchmark, pid=7329)[0m  80%|████████  | 400/500 [01:48<00:09, 10.17it/s]
[36m(vllm-benchmark, pid=7329)[0m  81%|████████  | 404/500 [01:48<00:06, 14.19it/s]
[36m(vllm-benchmark, pid=7329)[0m  81%|████████  | 406/500 [01:48<00:06, 14.56it/s]
[36m(vllm-benchmark, pid=7329)[0m  82%|████████▏ | 408/500 [01:48<00:06, 14.88it/s]
[36m(vllm-benchmark, pid=7329)[0m  82%|████████▏ | 410/500 [01:48<00:08, 11.10it/s]
[36m(vllm-benchmark, pid=7329)[0m  82%|████████▏ | 412/500 [01:49<00:07, 11.00it/s]
[36m(vllm-benchmark, pid=7329)[0m  83%|████████▎ | 414/500 [01:49<00:08, 10.03it/s]
[36m(vllm-benchmark, pid=7329)[0m  83%|████████▎ | 416/500 [01:49<00:07, 11.23it/s]
[36m(vllm-benchmark, pid=7329)[0m  84%|████████▎ | 418/500 [01:49<00:10,  8.00it/s]
[36m(vllm-benchmark, pid=7329)[0m  84%|████████▍ | 420/500 [01:50<00:08,  9.43it/s]
[36m(vllm-benchmark, pid=7329)[0m  84%|████████▍ | 422/500 [01:50<00:10,  7.30it/s]
[36m(vllm-benchmark, pid=7329)[0m  85%|████████▍ | 423/500 [01:51<00:19,  4.02it/s]
[36m(vllm-benchmark, pid=7329)[0m  85%|████████▌ | 425/500 [01:51<00:14,  5.10it/s]
[36m(vllm-benchmark, pid=7329)[0m  85%|████████▌ | 427/500 [01:51<00:11,  6.57it/s]
[36m(vllm-benchmark, pid=7329)[0m  86%|████████▌ | 429/500 [01:51<00:10,  6.62it/s]
[36m(vllm-benchmark, pid=7329)[0m  86%|████████▌ | 431/500 [01:51<00:08,  8.20it/s]
[36m(vllm-benchmark, pid=7329)[0m  87%|████████▋ | 433/500 [01:52<00:10,  6.38it/s]
[36m(vllm-benchmark, pid=7329)[0m  87%|████████▋ | 434/500 [01:52<00:11,  5.52it/s]
[36m(vllm-benchmark, pid=7329)[0m  87%|████████▋ | 435/500 [01:53<00:13,  4.93it/s]
[36m(vllm-benchmark, pid=7329)[0m  87%|████████▋ | 436/500 [01:53<00:12,  5.07it/s]
[36m(vllm-benchmark, pid=7329)[0m  87%|████████▋ | 437/500 [01:53<00:12,  4.94it/s]
[36m(vllm-benchmark, pid=7329)[0m  88%|████████▊ | 439/500 [01:53<00:10,  6.09it/s]
[36m(vllm-benchmark, pid=7329)[0m  88%|████████▊ | 441/500 [01:53<00:07,  8.12it/s]
[36m(vllm-benchmark, pid=7329)[0m  89%|████████▊ | 443/500 [01:54<00:11,  4.99it/s]
[36m(vllm-benchmark, pid=7329)[0m  89%|████████▉ | 445/500 [01:54<00:09,  5.64it/s]
[36m(vllm-benchmark, pid=7329)[0m  89%|████████▉ | 446/500 [01:54<00:08,  6.13it/s]
[36m(vllm-benchmark, pid=7329)[0m  90%|████████▉ | 448/500 [01:55<00:08,  6.24it/s]
[36m(vllm-benchmark, pid=7329)[0m  90%|█████████ | 450/500 [01:55<00:06,  8.09it/s]
[36m(vllm-benchmark, pid=7329)[0m  91%|█████████ | 453/500 [01:55<00:04, 10.76it/s]
[36m(vllm-benchmark, pid=7329)[0m  91%|█████████ | 455/500 [01:55<00:05,  7.74it/s]
[36m(vllm-benchmark, pid=7329)[0m  91%|█████████▏| 457/500 [01:55<00:05,  8.33it/s]
[36m(vllm-benchmark, pid=7329)[0m  92%|█████████▏| 459/500 [01:57<00:10,  3.82it/s]
[36m(vllm-benchmark, pid=7329)[0m  92%|█████████▏| 460/500 [01:57<00:11,  3.43it/s]
[36m(vllm-benchmark, pid=7329)[0m  92%|█████████▏| 462/500 [01:57<00:08,  4.41it/s]
[36m(vllm-benchmark, pid=7329)[0m  93%|█████████▎| 463/500 [01:58<00:08,  4.55it/s]
[36m(vllm-benchmark, pid=7329)[0m  93%|█████████▎| 465/500 [01:58<00:06,  5.45it/s]
[36m(vllm-benchmark, pid=7329)[0m  93%|█████████▎| 467/500 [01:58<00:04,  6.87it/s]
[36m(vllm-benchmark, pid=7329)[0m  94%|█████████▎| 468/500 [01:58<00:05,  5.57it/s]
[36m(vllm-benchmark, pid=7329)[0m  94%|█████████▍| 469/500 [01:59<00:11,  2.76it/s]
[36m(vllm-benchmark, pid=7329)[0m  94%|█████████▍| 471/500 [01:59<00:07,  3.75it/s]
[36m(vllm-benchmark, pid=7329)[0m  94%|█████████▍| 472/500 [02:00<00:06,  4.04it/s]
[36m(vllm-benchmark, pid=7329)[0m  95%|█████████▍| 473/500 [02:01<00:11,  2.41it/s]
[36m(vllm-benchmark, pid=7329)[0m  95%|█████████▍| 474/500 [02:01<00:10,  2.52it/s]
[36m(vllm-benchmark, pid=7329)[0m  95%|█████████▌| 475/500 [02:01<00:09,  2.61it/s]
[36m(vllm-benchmark, pid=7329)[0m  95%|█████████▌| 477/500 [02:02<00:06,  3.58it/s]
[36m(vllm-benchmark, pid=7329)[0m  96%|█████████▌| 478/500 [02:02<00:05,  3.99it/s]
[36m(vllm-benchmark, pid=7329)[0m  96%|█████████▌| 480/500 [02:03<00:08,  2.41it/s]
[36m(vllm-benchmark, pid=7329)[0m  96%|█████████▌| 481/500 [02:04<00:09,  2.10it/s]
[36m(vllm-benchmark, pid=7329)[0m  97%|█████████▋| 484/500 [02:04<00:04,  3.82it/s]
[36m(vllm-benchmark, pid=7329)[0m  97%|█████████▋| 486/500 [02:04<00:03,  3.92it/s]
[36m(vllm-benchmark, pid=7329)[0m  98%|█████████▊| 488/500 [02:05<00:02,  4.01it/s]
[36m(vllm-benchmark, pid=7329)[0m  98%|█████████▊| 489/500 [02:05<00:03,  3.38it/s]
[36m(vllm-benchmark, pid=7329)[0m  98%|█████████▊| 490/500 [02:05<00:02,  3.68it/s]
[36m(vllm-benchmark, pid=7329)[0m  98%|█████████▊| 492/500 [02:06<00:02,  3.13it/s]
[36m(vllm-benchmark, pid=7329)[0m  99%|█████████▊| 493/500 [02:07<00:02,  3.19it/s]
[36m(vllm-benchmark, pid=7329)[0m  99%|█████████▉| 494/500 [02:07<00:01,  3.66it/s]
[36m(vllm-benchmark, pid=7329)[0m  99%|█████████▉| 497/500 [02:07<00:00,  4.33it/s]
[36m(vllm-benchmark, pid=7329)[0m 100%|█████████▉| 498/500 [02:08<00:00,  4.00it/s]
[36m(vllm-benchmark, pid=7329)[0m 100%|█████████▉| 499/500 [02:08<00:00,  4.05it/s]
100%|██████████| 500/500 [02:08<00:00,  3.61it/s]
100%|██████████| 500/500 [02:08<00:00,  3.88it/s]
[36m(vllm-benchmark, pid=7329)[0m ============ Serving Benchmark Result ============
[36m(vllm-benchmark, pid=7329)[0m Successful requests:                     500       
[36m(vllm-benchmark, pid=7329)[0m Benchmark duration (s):                  128.72    
[36m(vllm-benchmark, pid=7329)[0m Total input tokens:                      102975    
[36m(vllm-benchmark, pid=7329)[0m Total generated tokens:                  107666    
[36m(vllm-benchmark, pid=7329)[0m Request throughput (req/s):              3.88      
[36m(vllm-benchmark, pid=7329)[0m Output token throughput (tok/s):         836.45    
[36m(vllm-benchmark, pid=7329)[0m Total Token throughput (tok/s):          1636.45   
[36m(vllm-benchmark, pid=7329)[0m ---------------Time to First Token----------------
[36m(vllm-benchmark, pid=7329)[0m Mean TTFT (ms):                          4026.12   
[36m(vllm-benchmark, pid=7329)[0m Median TTFT (ms):                        2113.11   
[36m(vllm-benchmark, pid=7329)[0m P99 TTFT (ms):                           14753.85  
[36m(vllm-benchmark, pid=7329)[0m -----Time per Output Token (excl. 1st token)------
[36m(vllm-benchmark, pid=7329)[0m Mean TPOT (ms):                          382.69    
[36m(vllm-benchmark, pid=7329)[0m Median TPOT (ms):                        247.31    
[36m(vllm-benchmark, pid=7329)[0m P99 TPOT (ms):                           1790.61   
[36m(vllm-benchmark, pid=7329)[0m ---------------Inter-token Latency----------------
[36m(vllm-benchmark, pid=7329)[0m Mean ITL (ms):                           222.31    
[36m(vllm-benchmark, pid=7329)[0m Median ITL (ms):                         163.57    
[36m(vllm-benchmark, pid=7329)[0m P99 ITL (ms):                            642.50    
[36m(vllm-benchmark, pid=7329)[0m ==================================================
[36m(vllm-benchmark, pid=7329)[0m + sleep 6
[36m(vllm-benchmark, pid=7329)[0m uv run --with rich --with pandas extract-result.py results/deepseek-r1
[36m(vllm-benchmark, pid=7329)[0m 
[36m(vllm-benchmark, pid=7329)[0m Loading results from /home/ubuntu/vLLM-Benchmark/results/deepseek-r1
[36m(vllm-benchmark, pid=7329)[0m Found 10 JSON files
[36m(vllm-benchmark, pid=7329)[0m Processing sgl-1000-2000-.json
[36m(vllm-benchmark, pid=7329)[0m Processing vllm-30000-100-.json
[36m(vllm-benchmark, pid=7329)[0m Processing vllm-sharegpt-.json
[36m(vllm-benchmark, pid=7329)[0m Processing vllm-10000-500-.json
[36m(vllm-benchmark, pid=7329)[0m Processing sgl-sharegpt-.json
[36m(vllm-benchmark, pid=7329)[0m Processing sgl-5000-1000-.json
[36m(vllm-benchmark, pid=7329)[0m Processing vllm-5000-1000-.json
[36m(vllm-benchmark, pid=7329)[0m Processing vllm-1000-2000-.json
[36m(vllm-benchmark, pid=7329)[0m Processing sgl-30000-100-.json
[36m(vllm-benchmark, pid=7329)[0m Processing sgl-10000-500-.json
[36m(vllm-benchmark, pid=7329)[0m Successfully loaded data with columns: ['backend', 'input_tokens', 
[36m(vllm-benchmark, pid=7329)[0m 'output_tokens', 'output_toks/s']
[36m(vllm-benchmark, pid=7329)[0m 
[36m(vllm-benchmark, pid=7329)[0m Data Preview:
[36m(vllm-benchmark, pid=7329)[0m   backend input_tokens output_tokens  output_toks/s
[36m(vllm-benchmark, pid=7329)[0m 0     sgl         1000          2000     971.492219
[36m(vllm-benchmark, pid=7329)[0m 1    vllm        30000           100      37.030036
[36m(vllm-benchmark, pid=7329)[0m 2    vllm     sharegpt      sharegpt    1323.743725
[36m(vllm-benchmark, pid=7329)[0m 3    vllm        10000           500     440.847598
[36m(vllm-benchmark, pid=7329)[0m 4     sgl     sharegpt      sharegpt     836.448526
[36m(vllm-benchmark, pid=7329)[0m 5     sgl         5000          1000     813.825354
[36m(vllm-benchmark, pid=7329)[0m 6    vllm         5000          1000     846.071516
[36m(vllm-benchmark, pid=7329)[0m 7    vllm         1000          2000    1124.662662
[36m(vllm-benchmark, pid=7329)[0m 8     sgl        30000           100      33.110662
[36m(vllm-benchmark, pid=7329)[0m 9     sgl        10000           500     390.349846
[36m(vllm-benchmark, pid=7329)[0m 
[36m(vllm-benchmark, pid=7329)[0m   input_tokens output_tokens  ...  gap_vllm_to_sgl_output_toks/s  vllm_output_toks/s
[36m(vllm-benchmark, pid=7329)[0m 0         1000          2000  ...                      15.766513         1124.662662
[36m(vllm-benchmark, pid=7329)[0m 1         5000          1000  ...                       3.962295          846.071516
[36m(vllm-benchmark, pid=7329)[0m 2        10000           500  ...                      12.936537          440.847598
[36m(vllm-benchmark, pid=7329)[0m 3        30000           100  ...                      11.837196           37.030036
[36m(vllm-benchmark, pid=7329)[0m 4     sharegpt      sharegpt  ...                      58.257643         1323.743725
[36m(vllm-benchmark, pid=7329)[0m 
[36m(vllm-benchmark, pid=7329)[0m [5 rows x 5 columns]
[36m(vllm-benchmark, pid=7329)[0m           Benchmark Comparison for vLLM (Output Tokens/s)           
[36m(vllm-benchmark, pid=7329)[0m ┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━━━━━┓
[36m(vllm-benchmark, pid=7329)[0m ┃ Input Tokens ┃ Output Tokens ┃    vLLM ┃    SGL ┃ vLLM/SGL Gap % ┃
[36m(vllm-benchmark, pid=7329)[0m ┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━━━━━┩
[36m(vllm-benchmark, pid=7329)[0m │         1000 │          2000 │ 1124.66 │ 971.49 │        +15.77% │
[36m(vllm-benchmark, pid=7329)[0m │         5000 │          1000 │  846.07 │ 813.83 │         +3.96% │
[36m(vllm-benchmark, pid=7329)[0m │        10000 │           500 │  440.85 │ 390.35 │        +12.94% │
[36m(vllm-benchmark, pid=7329)[0m │        30000 │           100 │   37.03 │  33.11 │        +11.84% │
[36m(vllm-benchmark, pid=7329)[0m │     sharegpt │      sharegpt │ 1323.74 │ 836.45 │        +58.26% │
[36m(vllm-benchmark, pid=7329)[0m └──────────────┴───────────────┴─────────┴────────┴────────────────┘
[36m(vllm-benchmark, pid=7329)[0m                          Model: deepseek-r1                         
[36m(vllm-benchmark, pid=7329)[0m ----- CSV for Easy Plotting -----
[36m(vllm-benchmark, pid=7329)[0m input_tokens,output_tokens,sgl_output_toks/s,gap_vllm_to_sgl_output_toks/s,vllm_
[36m(vllm-benchmark, pid=7329)[0m output_toks/s
[36m(vllm-benchmark, pid=7329)[0m 1000,2000,971.4922188112355,15.766512652506734,1124.6626624082273
[36m(vllm-benchmark, pid=7329)[0m 5000,1000,813.8253543275932,3.9622950989598773,846.0715164562083
[36m(vllm-benchmark, pid=7329)[0m 10000,500,390.3498458397235,12.936536984473216,440.8475980156135
[36m(vllm-benchmark, pid=7329)[0m 30000,100,33.11066175480388,11.837195956372899,37.03003566917183
[36m(vllm-benchmark, pid=7329)[0m sharegpt,sharegpt,836.4485255719942,58.25764336167224,1323.7437245036924
[36m(vllm-benchmark, pid=7329)[0m 
[0m[32m✓ Job finished (status: SUCCEEDED).[0m
